[
  {
    "objectID": "misc/how-to.html",
    "href": "misc/how-to.html",
    "title": "Oslo Bioinformatics",
    "section": "",
    "text": "The course website\nThe website is linked to the github repository, specifically,\n\nHomepage links to index.qmd\nPreparation links to part0_prep.qmd\nR Lab - Part I links to part1_eda.qmd\nR Lab - Part II links to part2_model.qmd\nAbout links to about.qmd\n\nThe overall appearance is controlled by _quarto.yml.\n\n\nHow to modify the content\nThe website is made by quarto, which is a better version of Rmarkdown. The way code chunk works is exactly the same as Rmarkdown (only that it supports a few more languages in the same file).\nYou might need to install quarto and upgrade Rstudio to the latest version, to be able to render the documents by yourself.\nMake sure that the path are set properly so that files can be loaded properly.\nDeploy changes to the website: push all modifications to github, the site will update itself momentarily (after the CI/CD are successful)\nYou can also let me know if you need any help with the website or text."
  },
  {
    "objectID": "part0_prep.html",
    "href": "part0_prep.html",
    "title": "Preparation",
    "section": "",
    "text": "Here are some preparation information for the participants."
  },
  {
    "objectID": "part0_prep.html#software",
    "href": "part0_prep.html#software",
    "title": "Preparation",
    "section": "Software",
    "text": "Software\nIn this workshop we will be using R. You can either\n\nhave R and Rstudio installed on your laptop\nor, use Posit cloud (formerly Rstudio Cloud).\n\nPosit cloud is free of charge for personal users, yet you need to sign up for a new user account and have internet connection. Use this Posit cloud project: https://posit.cloud/content/5131383.\nNote: In the Posit cloud project, all required R code and data sets should already be available, and all required R packages are already installed. If you plan to use your own laptop and local RStudio setup, then you will need to download the data and R code and install"
  },
  {
    "objectID": "part0_prep.html#data",
    "href": "part0_prep.html#data",
    "title": "Preparation",
    "section": "Data",
    "text": "Data\nThe datasets we use can be found here."
  },
  {
    "objectID": "part0_prep.html#code",
    "href": "part0_prep.html#code",
    "title": "Preparation",
    "section": "Code",
    "text": "Code\nThe R scripts used in part 1 and part 2 can be found here."
  },
  {
    "objectID": "part0_prep.html#resources",
    "href": "part0_prep.html#resources",
    "title": "Preparation",
    "section": "Resources",
    "text": "Resources\nLecture notes link\nLab notes link\nAure 2015 Paper link"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MED3007: Statistical Principles in Genomics",
    "section": "",
    "text": "Welcome!\nThis is the course website for MED3007: Statistical Principles in Genomics at the Faculty of Medicine, University of Oslo.\nThe course website is developed by the instructors of the course, hosted for free and public accessible on Github. Course material can be found in the github repository.\n\nStructure\n\nGet Started provides some information about software installation, data download and code.\nR Lab and Code hosts the lab session exercises and code.\n\n\n\n\n\n\n\nOfficial course webpage\n\n\n\nPlease refer to the official course page by University of Oslo for information related to application, evaluation and other administrative matters.\n\n\n\n\nPreparation before the course starts\nYou should have R installed on your computer before the course. More on preparation please read here.\nIf you have trouble setting it up with your own laptop, you can also use the PC in the PC lab.\n\n\n\nSchedule\nYou can find the time and place on the official course schedule at the University of Oslo course website.\nIf there is a conflict of information, please refer to the official schedule.\n\nDay 1\n\n\n\nTime\nTopic\nCourse material\n\n\n\n\n9:00 - 9:45\nIntroduction to the course\nLecture\n\n\n10:00 - 11:30\nLab: Introduction to R and Rstudio\nLab: intro to R, Code\n\n\n13:00 - 14:00\nData screening and multiple testing\nLecture\n\n\n14:00 - 16:00\nQ&A\n\n\n\n\n\n\nDay 2\n\n\n\nTime\nTopic\nCourse material\n\n\n\n\n9:00 - 9:45\nLab: Data screening and multiple testing\n\n\n\n10:00 - 11:30\nExercises\nLab: multiple testing, Code, Code (solution)\n\n\n13:00 - 14:00\nData visualization, dimensional reduction\nLecture\n\n\n14:00 - 16:00\nQ&A\n\n\n\n\n\n\nDay 3\n\n\n\nTime\nTopic\nCourse material\n\n\n\n\n9:00 - 9:45\nLab: Data visualization, dimensional reduction\nLecture\n\n\n10:00 - 11:30\nExercises\nLab: PCA, Code\n\n\n13:00 - 14:00\nClustering\nLecture\n\n\n14:00 - 16:00\nQ&A\n\n\n\n\n\n\nDay 4\n\n\n\nTime\nTopic\nCourse material\n\n\n\n\n9:00 - 9:45\nLab: Clustering and heatmaps\n\n\n\n10:00 - 11:30\nExercises\nLab: clustering, Code\n\n\n13:00 - 14:00\nTake-home exam simulation\n\n\n\n14:00 - 16:00\nQ&A"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About MED3007",
    "section": "",
    "text": "Genomic data analysis is increasingly important both in medical research and in the clinical practice. In this course, you will learn the basic principles and concepts in the statistical analysis of genomic data. The course will focus on the three main tasks that are frequently involved in genomics: data visualisation, data screening and pre-processing, data modelling (prediction and classification). You will get a practical introduction to RStudio, the best statistical software for analysing genomic data, thus enabling you to perform basic programming tasks, to visualise and analyse genomic data, and to interpret the results.\n\n\nValeria Vitelli (course lead): valeria.vitelli@medisin.uio.no\nChi Zhang (R lab sessions): chi.zhang@medisin.uio.no"
  },
  {
    "objectID": "part1_eda.html",
    "href": "part1_eda.html",
    "title": "R Lab - Part I",
    "section": "",
    "text": "See StatPrinciples_RLab.pdf for some background info.\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses in Aure et al. (2015). Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are three extra tasks Task 1, Task 2, Task 3, where no R code is provided. Please do these tasks when you have time available at the end of the lab.\n\n\n\ninstall.packages(\"glmnet\")\ninstall.packages(\"gclus\")\n\n\n\n\nRead the data, and convert to matrix format.\n\nmir &lt;- read.table(\"lab/data/miRNA-421x282.txt\", header=T, sep=\"\\t\", dec=\".\")\nrna &lt;- read.table(\"lab/data/mRNA-100x282.txt\", header=T, sep=\"\\t\", dec=\".\")\nprt &lt;- read.table(\"lab/data/prot-100x282.txt\", header=T, sep=\"\\t\", dec=\".\")\n\n# Convert to matrix format\n\nmir &lt;- as.matrix(mir)\nrna &lt;- as.matrix(rna)\nprt &lt;- as.matrix(prt)\n\nPrint the data\n\nmir[1:4, 1:4]\n\n            OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nhsa-let-7a      -1.10330      0.40033     -0.65364      0.78277\nhsa-let-7a*     -0.58049     -0.72246      1.46023     -0.67980\nhsa-let-7b      -3.17134      0.41602     -0.13054      1.11872\nhsa-let-7c      -3.10923      0.27861     -0.17365      0.47395\n\nrna[1:4, 1:4]\n\n      OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nACACA      1.60034     -0.49087     -0.26553     -0.27857\nANXA1     -2.42501     -0.05416     -0.46478     -2.18393\nAR         0.39615     -0.43348     -0.10232      0.58299\nBAK1       0.78627      0.39897      0.22598     -1.31202\n\nprt[1:4, 1:4]\n\n      OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nACACA      0.48181     -0.76244      0.22878      0.02493\nANXA1     -0.37323      0.52558      0.73313     -1.60107\nAR         1.39394     -0.33711      0.07152      1.51886\nBAK1       1.44828      1.26768     -0.32807      1.41299\n\n\nVisualise the overall distribution of expression levels by histogram\n\npar(mfrow=c(3,1))\nhist(mir, nclass=40, xlim=c(-5,5), col=\"lightblue\")\nhist(rna, nclass=40, xlim=c(-5,5), col=\"lightblue\")\nhist(prt, nclass=40, xlim=c(-5,5), col=\"lightblue\")\n\n\n\n\nmRNA-protein associations (only first nine genes)\n\npar(mfrow=c(3,3))\npar(mar=c(3,3,3,3))\nfor (i in 1:9) {\n  plot(rna[i,], prt[i,], pch=19)\n  title(rownames(rna)[i])\n  lines(smooth.spline(rna[i,], prt[i,], df=4), col=\"red\")\n}\n\n\n\n\n\n\n\n\n\n\nTask 1\n\n\n\nExtend the above analysis to cover all genes."
  },
  {
    "objectID": "part1_eda.html#explore-the-correlations",
    "href": "part1_eda.html#explore-the-correlations",
    "title": "R Lab - Part I",
    "section": "Explore the correlations",
    "text": "Explore the correlations\nCompute and plot mRNA-protein correlations\n\nrho = rep(NA, nrow(rna))  \nfor (i in 1:nrow(rna)) {\n  rho[i] = cor(rna[i,], prt[i,])\n}\npar(mfrow=c(1,1))\nhist(rho, col=\"lightblue\")\n\n\n\n\nCalculate the correlation of each miRNA to each protein\n\nRHO = matrix(NA, nrow(mir), nrow(prt))\nfor (i in 1:nrow(mir)) {\n  for (j in 1:nrow(prt)) {\n     RHO[i,j] = cor(mir[i,], prt[j,]) \n  }\n}\npar(mfrow=c(1,1))\nhist(RHO, col=\"lightblue\")"
  },
  {
    "objectID": "part1_eda.html#visualize-as-heatmap",
    "href": "part1_eda.html#visualize-as-heatmap",
    "title": "R Lab - Part I",
    "section": "Visualize as heatmap",
    "text": "Visualize as heatmap\nUse the code provided to visualize the heatmap.\nNote: If you get the error message Error in plot.new() : figure margins too large, try to increase the Plots panel in your RStudio workspace.\n\nsource(\"lab/code/clustermap_beta.R\")\n\nplot.init(tree=c(2,3))\nhcluster(RHO, clust=\"row\", distance=\"euclidean\", linkage=\"complete\")\nhcluster(RHO, clust=\"col\", distance=\"euclidean\", linkage=\"complete\")\nplot.hmap(RHO)\nplot.tree(side=2)\nplot.tree(side=3)\nplot.hmap.key()\n\n\n\n\n\n\n\nTask 2\n\n\n\nCompare this heatmap with Figure 3 in Aure et al. (2015). Are these two figures showing the same results?"
  },
  {
    "objectID": "part2_model.html",
    "href": "part2_model.html",
    "title": "R Lab - Part II",
    "section": "",
    "text": "In this part of the exercise, we model (on the log-scale) the association of miRNA espression on protein expression adjusting for the corresponding mRNA.\nInvestigate miR-107 and B-RAF (Aure et al, 2015, Figure 2H)\n\nprt.BRAF = prt[12,]\nrna.BRAF = rna[12,]\nmir.107 = mir[16,] \n\n\n\non the log-scale, Aure et al. 2015, equation (3)\n\nfitA &lt;- lm(prt.BRAF ~ mir.107 + rna.BRAF)\nsummary(fitA)\n\n\nCall:\nlm(formula = prt.BRAF ~ mir.107 + rna.BRAF)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3028 -0.6126  0.0453  0.6153  3.1361 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -7.315e-08  5.068e-02   0.000        1    \nmir.107      4.324e-01  5.079e-02   8.513 1.06e-15 ***\nrna.BRAF     3.200e-01  5.079e-02   6.301 1.15e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.851 on 279 degrees of freedom\nMultiple R-squared:  0.281, Adjusted R-squared:  0.2758 \nF-statistic: 54.51 on 2 and 279 DF,  p-value: &lt; 2.2e-16\n\n\nAdd smooth non-linear cures to the scatterplots: use existing panel.smooth() function, and add linear regression lines to the scatterplots:\n\npanel.linear &lt;- function (x, y, col.regres = \"blue\", ...) \n{ \n  points(x, y, pch=19) \n  ok &lt;- is.finite(x) & is.finite(y) \n  if (any(ok)) \n    abline(stats::lm(y[ok] ~ x[ok]), col = col.regres, ...) \n} \n\npairs(data.frame(mir.107, prt.BRAF, rna.BRAF), \n      lower.panel = panel.smooth,\n      upper.panel = panel.linear)\n\n\n\n\n\n\n\nwith all miRNAs (Aure et al. 2015, equation (4))\n\nlibrary(glmnet)\n\n# 10-fold CV to determine the optimal lambda:\n# Note: rna.BRAF is penalised together with all the mir variables. \n# You can use the penalty.factor option to avoid this.\nset.seed(1234)\ncvfit &lt;- cv.glmnet(y=prt.BRAF, x=t(rbind(mir, rna.BRAF)),\n                   alpha=1, nfolds=10, standardize=TRUE)\n\npar(mfrow=c(1,1))\nplot(cvfit)\nlambda.opt &lt;- cvfit$lambda.min\n\n# Coefficient path plot and coefficients for optimal lambda:\nfitB &lt;- cvfit$glmnet.fit\n\nplot(fitB, xvar=\"lambda\")\nabline(v=log(lambda.opt))\n\ncoef(fitB, s=lambda.opt)\npredict(fitB, type=\"nonzero\", s=lambda.opt)\n\nCompare the regression coefficient of mir.107 from the models in (a) and (b):\n\ncoef(fitA)[\"mir.107\"]\nas.matrix(coef(fitB, s=cvfit$lambda.min))[\"hsa-miR-107\",]\n\n\n\n\n\n\n\nTask 3\n\n\n\nRepeat the lasso analysis, but this time do not penalise the rna.BRAF variable together with the mir variables.\nCheck out the information on the penalty.factor option in ?glmnet to understand how."
  },
  {
    "objectID": "part0_prep.html#required-r-packages",
    "href": "part0_prep.html#required-r-packages",
    "title": "Preparation",
    "section": "Required R packages",
    "text": "Required R packages\nThe R package we are using is glmnet. Otherwise, we use base R packages which are already installed by default. We will also need R package gclus for one of the tasks (not essential for running other parts of the lab). You can install the packages by running the following code:\ninstall.packages(\"glmnet\")\ninstall.packages(\"gclus\")"
  },
  {
    "objectID": "part2_model.html#association-modeling",
    "href": "part2_model.html#association-modeling",
    "title": "R Lab - Part II",
    "section": "",
    "text": "In this part of the exercise, we model (on the log-scale) the association of miRNA espression on protein expression adjusting for the corresponding mRNA.\nInvestigate miR-107 and B-RAF (Aure et al, 2015, Figure 2H)\n\nprt.BRAF = prt[12,]\nrna.BRAF = rna[12,]\nmir.107 = mir[16,] \n\n\n\non the log-scale, Aure et al. 2015, equation (3)\n\nfitA &lt;- lm(prt.BRAF ~ mir.107 + rna.BRAF)\nsummary(fitA)\n\n\nCall:\nlm(formula = prt.BRAF ~ mir.107 + rna.BRAF)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3028 -0.6126  0.0453  0.6153  3.1361 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -7.315e-08  5.068e-02   0.000        1    \nmir.107      4.324e-01  5.079e-02   8.513 1.06e-15 ***\nrna.BRAF     3.200e-01  5.079e-02   6.301 1.15e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.851 on 279 degrees of freedom\nMultiple R-squared:  0.281, Adjusted R-squared:  0.2758 \nF-statistic: 54.51 on 2 and 279 DF,  p-value: &lt; 2.2e-16\n\n\nAdd smooth non-linear cures to the scatterplots: use existing panel.smooth() function, and add linear regression lines to the scatterplots:\n\npanel.linear &lt;- function (x, y, col.regres = \"blue\", ...) \n{ \n  points(x, y, pch=19) \n  ok &lt;- is.finite(x) & is.finite(y) \n  if (any(ok)) \n    abline(stats::lm(y[ok] ~ x[ok]), col = col.regres, ...) \n} \n\npairs(data.frame(mir.107, prt.BRAF, rna.BRAF), \n      lower.panel = panel.smooth,\n      upper.panel = panel.linear)\n\n\n\n\n\n\n\nwith all miRNAs (Aure et al. 2015, equation (4))\n\nlibrary(glmnet)\n\n# 10-fold CV to determine the optimal lambda:\n# Note: rna.BRAF is penalised together with all the mir variables. \n# You can use the penalty.factor option to avoid this.\nset.seed(1234)\ncvfit &lt;- cv.glmnet(y=prt.BRAF, x=t(rbind(mir, rna.BRAF)),\n                   alpha=1, nfolds=10, standardize=TRUE)\n\npar(mfrow=c(1,1))\nplot(cvfit)\nlambda.opt &lt;- cvfit$lambda.min\n\n# Coefficient path plot and coefficients for optimal lambda:\nfitB &lt;- cvfit$glmnet.fit\n\nplot(fitB, xvar=\"lambda\")\nabline(v=log(lambda.opt))\n\ncoef(fitB, s=lambda.opt)\npredict(fitB, type=\"nonzero\", s=lambda.opt)\n\nCompare the regression coefficient of mir.107 from the models in (a) and (b):\n\ncoef(fitA)[\"mir.107\"]\nas.matrix(coef(fitB, s=cvfit$lambda.min))[\"hsa-miR-107\",]\n\n\n\n\n\n\n\nTask 3\n\n\n\nRepeat the lasso analysis, but this time do not penalise the rna.BRAF variable together with the mir variables.\nCheck out the information on the penalty.factor option in ?glmnet to understand how."
  },
  {
    "objectID": "part1_eda.html#a-cancer-modeling-example",
    "href": "part1_eda.html#a-cancer-modeling-example",
    "title": "R Lab - Part I",
    "section": "",
    "text": "See StatPrinciples_RLab.pdf for some background info.\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses in Aure et al. (2015). Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are three extra tasks Task 1, Task 2, Task 3, where no R code is provided. Please do these tasks when you have time available at the end of the lab.\n\n\n\ninstall.packages(\"glmnet\")\ninstall.packages(\"gclus\")\n\n\n\n\nRead the data, and convert to matrix format.\n\nmir &lt;- read.table(\"lab/data/miRNA-421x282.txt\", header=T, sep=\"\\t\", dec=\".\")\nrna &lt;- read.table(\"lab/data/mRNA-100x282.txt\", header=T, sep=\"\\t\", dec=\".\")\nprt &lt;- read.table(\"lab/data/prot-100x282.txt\", header=T, sep=\"\\t\", dec=\".\")\n\n# Convert to matrix format\n\nmir &lt;- as.matrix(mir)\nrna &lt;- as.matrix(rna)\nprt &lt;- as.matrix(prt)\n\nPrint the data\n\nmir[1:4, 1:4]\n\n            OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nhsa-let-7a      -1.10330      0.40033     -0.65364      0.78277\nhsa-let-7a*     -0.58049     -0.72246      1.46023     -0.67980\nhsa-let-7b      -3.17134      0.41602     -0.13054      1.11872\nhsa-let-7c      -3.10923      0.27861     -0.17365      0.47395\n\nrna[1:4, 1:4]\n\n      OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nACACA      1.60034     -0.49087     -0.26553     -0.27857\nANXA1     -2.42501     -0.05416     -0.46478     -2.18393\nAR         0.39615     -0.43348     -0.10232      0.58299\nBAK1       0.78627      0.39897      0.22598     -1.31202\n\nprt[1:4, 1:4]\n\n      OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nACACA      0.48181     -0.76244      0.22878      0.02493\nANXA1     -0.37323      0.52558      0.73313     -1.60107\nAR         1.39394     -0.33711      0.07152      1.51886\nBAK1       1.44828      1.26768     -0.32807      1.41299\n\n\nVisualise the overall distribution of expression levels by histogram\n\npar(mfrow=c(3,1))\nhist(mir, nclass=40, xlim=c(-5,5), col=\"lightblue\")\nhist(rna, nclass=40, xlim=c(-5,5), col=\"lightblue\")\nhist(prt, nclass=40, xlim=c(-5,5), col=\"lightblue\")\n\n\n\n\nmRNA-protein associations (only first nine genes)\n\npar(mfrow=c(3,3))\npar(mar=c(3,3,3,3))\nfor (i in 1:9) {\n  plot(rna[i,], prt[i,], pch=19)\n  title(rownames(rna)[i])\n  lines(smooth.spline(rna[i,], prt[i,], df=4), col=\"red\")\n}\n\n\n\n\n\n\n\n\n\n\nTask 1\n\n\n\nExtend the above analysis to cover all genes."
  },
  {
    "objectID": "about.html#course-content",
    "href": "about.html#course-content",
    "title": "About MED3007",
    "section": "",
    "text": "Genomic data analysis is increasingly important both in medical research and in the clinical practice. In this course, you will learn the basic principles and concepts in the statistical analysis of genomic data. The course will focus on the three main tasks that are frequently involved in genomics: data visualisation, data screening and pre-processing, data modelling (prediction and classification). You will get a practical introduction to RStudio, the best statistical software for analysing genomic data, thus enabling you to perform basic programming tasks, to visualise and analyse genomic data, and to interpret the results.\n\n\nValeria Vitelli (course lead): valeria.vitelli@medisin.uio.no\nChi Zhang (R lab sessions): chi.zhang@medisin.uio.no"
  },
  {
    "objectID": "get_started/get_started.html",
    "href": "get_started/get_started.html",
    "title": "Get started",
    "section": "",
    "text": "In this course we will be using R and Rstudio. You can either\n\n(recommended) have R and Rstudio installed on your laptop\nor, use the PC in the PC lab here at the university\n\n\n\n\n\n\n\nTip\n\n\n\nWatch these YouTube videos if you want a step-by-step guide.\n\n\n\nSet up your RStudio on your laptop\nYou will need both R and Rstudio, they are two separate things.\nYou can download Rstudio here. In this page it will ask you to install R, so it should be clear to follow.\n\nYou can download R for Linux, macOS or Windows here or here\n\nOnce you have finished installing both R and Rstudio, open Rstudio, and you should be seeing something like this:\n\n\n\nData\nYou can download the datasets from either our GitHub repository, or Canvas.\n\nDownload data from Canvas\nLog in your Canvas page, locate the dataset, and click “download”.\n\n\nDownload data from GitHub\nThe datasets used in this course are stored in this folder.\n\nGo to the repository, select the data you want to download by left-click the file name\nIf it is a dataset in .csv, .txt format, you will see something like this\n\n\n\nfind Raw button, right-click, you will see a list of options\nchoose Download Linked File, this will download the data into your default download folder\nalternatively, choose Download linked file as… so that you can change where you put it and file name.\n\n\nIf it is a dataset in .dta, .xlsx or other format, you might not see the data directly:\n\n\n\nfind Download button, left-click, and you will download it into your default download folder.\n\n\nOptional: download data via URL\nIf you feel like it, you can also download data inside R via URL. You can read more about it here.\n\n\n\n\nCode\nR scripts are stored in this folder.\nTo download an R script, it is similar to downloading a dataset\n\nAlternatively, you can create your own R script locally inside Rstudio, by copy and paste the script from Github."
  },
  {
    "objectID": "lab/overview.html",
    "href": "lab/overview.html",
    "title": "R Lab: Overview",
    "section": "",
    "text": "day 2 (MT)\n\nbrainshake (t-test)\nNCI60 (t-test, multiple testing)\nCh10Ex11\n\nday 3 (PCA)\n\nFood\nNCI60\nCH10Ex11\n\nday 4 (clustering)\n\nNCI60\nCH10Ex11"
  },
  {
    "objectID": "lab/overview.html#a-cancer-modeling-example",
    "href": "lab/overview.html#a-cancer-modeling-example",
    "title": "R Lab - Part I",
    "section": "",
    "text": "See StatPrinciples_RLab.pdf for some background info.\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses in Aure et al. (2015). Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are three extra tasks Task 1, Task 2, Task 3, where no R code is provided. Please do these tasks when you have time available at the end of the lab.\n\n\n\n\n\nRead the data, and convert to matrix format."
  },
  {
    "objectID": "lecture_notes/overview.html",
    "href": "lecture_notes/overview.html",
    "title": "Overview",
    "section": "",
    "text": "See StatPrinciples_RLab.pdf for some background info.\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses in Aure et al. (2015). Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are three extra tasks Task 1, Task 2, Task 3, where no R code is provided. Please do these tasks when you have time available at the end of the lab."
  },
  {
    "objectID": "lecture_notes/overview.html#a-cancer-modeling-example",
    "href": "lecture_notes/overview.html#a-cancer-modeling-example",
    "title": "Overview",
    "section": "",
    "text": "See StatPrinciples_RLab.pdf for some background info.\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses in Aure et al. (2015). Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are three extra tasks Task 1, Task 2, Task 3, where no R code is provided. Please do these tasks when you have time available at the end of the lab."
  },
  {
    "objectID": "lab/lab_day1_intro.html",
    "href": "lab/lab_day1_intro.html",
    "title": "Introduction to R",
    "section": "",
    "text": "R is a language and environment for statistical computing, data analysis, visualisation and graphics and many more. It is a free and open source software, under the terms of GNU General Public License.\nR runs on a wide variety of platforms, including Windows, Linux and MacOS."
  },
  {
    "objectID": "lab/lab_day1_intro.html#a-cancer-modeling-example",
    "href": "lab/lab_day1_intro.html#a-cancer-modeling-example",
    "title": "R Lab - Part I",
    "section": "",
    "text": "See StatPrinciples_RLab.pdf for some background info.\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses in Aure et al. (2015). Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are three extra tasks Task 1, Task 2, Task 3, where no R code is provided. Please do these tasks when you have time available at the end of the lab.\n\n\n\n\n\nRead the data, and convert to matrix format."
  },
  {
    "objectID": "lab/overview.html#datasets",
    "href": "lab/overview.html#datasets",
    "title": "R Lab: Overview",
    "section": "",
    "text": "day 2 (MT)\n\nbrainshake (t-test)\nNCI60 (t-test, multiple testing)\nCh10Ex11\n\nday 3 (PCA)\n\nFood\nNCI60\nCH10Ex11\n\nday 4 (clustering)\n\nNCI60\nCH10Ex11"
  },
  {
    "objectID": "lab/lab_day2_pca.html",
    "href": "lab/lab_day2_pca.html",
    "title": "R Lab (day 2): PCA",
    "section": "",
    "text": "Datasets\nR script"
  },
  {
    "objectID": "lab/lab_day2_pca.html#nci60",
    "href": "lab/lab_day2_pca.html#nci60",
    "title": "R Lab (day 2): PCA",
    "section": "NCI60",
    "text": "NCI60\n\nlibrary(ISLR)\nnci.labs &lt;- NCI60$labs # Sample labels (tissue type)\nnci.data &lt;- NCI60$data # Gene expression data set\n\n\n# what if I would like to compute the mean of each gene within each tissue type?\ntissue.means &lt;- apply(nci.data, 2, function(x){tapply(x, nci.labs, mean)})\ndim(tissue.means)\n\n[1]   14 6830\n\ntable(nci.labs)\n\nnci.labs\n     BREAST         CNS       COLON K562A-repro K562B-repro    LEUKEMIA \n          7           5           7           1           1           6 \nMCF7A-repro MCF7D-repro    MELANOMA       NSCLC     OVARIAN    PROSTATE \n          1           1           8           9           6           2 \n      RENAL     UNKNOWN \n          9           1 \n\n\nCompute the PC\n\n# PCA analysis after scaling the variables to standard deviation one:\npr.out &lt;- prcomp(nci.data, scale=TRUE)\n\nPrint the summary output\n\nsummary(pr.out)\n\n\npr.var &lt;- pr.out$sdev^2\npve &lt;- pr.var/sum(pr.var)\npve &lt;- 100*pve\n\npar(mfrow=c(1,2))\nplot(pve,  type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"brown3\")\n\n\n\n\n\nHow many PCs to keep?\n\nmysel80 &lt;- which(cumsum(pve) &gt; 80)[1] # explains 80% of the variability\nmysel70 &lt;- which(cumsum(pve) &gt; 70)[1] # explains 70% of the variability\n\npar(mfrow=c(1,2)) # plot contains two smaller plots next to each other\nplot(pve,  type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nabline(v = mysel80)\nabline(v = mysel70, col=3)\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"brown3\")\nabline(v = mysel80)\nabline(h = 80)\nabline(v = mysel70, col=3)\nabline(h = 70, col=3)\n\n\n\n\nIf we decide to only keep the principal components that explains 70% of the variance, we end up with 24 components, which we can further analyse to better understand the relationships between the variables. For simplicity we only look at the first few components.\nWe plot the first few principal component score vectors, to visualize the results. The observations (cell lines) corresponding to a given cancer type will be plotted in the same colour.\n\nCols=function(vec){\n  cols=rainbow(length(unique(vec)))\n  return(cols[as.numeric(as.factor(vec))])\n}\n\n# Plot the first vs second and first vs third principal component score vectors,\n# with colors associated to labels (using the Cols() helper function)\npar(mfrow=c(1,2))\nplot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19,xlab=\"PC 1\",ylab=\" PC 2\")\nplot(pr.out$x[,c(1,3)], col=Cols(nci.labs), pch=19,xlab=\"PC 1\",ylab=\" PC 3\")\nlegend('topleft', col=rainbow(length(unique(nci.labs))), legend=unique(nci.labs), bty='n', lwd=2, cex=.6)"
  },
  {
    "objectID": "lab/overview.html#lab-notes-and-r-scripts",
    "href": "lab/overview.html#lab-notes-and-r-scripts",
    "title": "R Lab: Overview",
    "section": "Lab notes and R scripts",
    "text": "Lab notes and R scripts\n\n\n\nDay\nLab notes\nR script\n\n\n\n\nDay 1\nDay 1: Introduction to R\nCode\n\n\n\nDay 1 (supplement): Navigate RStudio and workspace\n\n\n\nDay 2\nDay 2: Multiple testing\nCode, Code (solution)\n\n\nDay 3\nDay 3: Principal Component Analysis\nCode\n\n\nDay 4\nDay 4: Clustering\nCode"
  },
  {
    "objectID": "lab/lab_day3_pca.html",
    "href": "lab/lab_day3_pca.html",
    "title": "R Lab (day 3): Data exploration, Principal Component Analysis",
    "section": "",
    "text": "Download datasets here or from Canvas.\nR script: Code\nLab Lecture"
  },
  {
    "objectID": "lab/lab_day3_pca.html#nci60",
    "href": "lab/lab_day3_pca.html#nci60",
    "title": "R Lab (day 3): Principal Component Analysis",
    "section": "NCI60",
    "text": "NCI60\nNow we move to a typical large-scale biological data set (this is partly based on Lab 10.3 in James et al., 2013).\nWe have already seen the NCI60 cancer cell line microarray data set, consisting of 6830 gene expression measurements on 64 cancer cell lines.\n\nlibrary(ISLR)\nnci.labs &lt;- NCI60$labs # Sample labels (tissue type)\nnci.data &lt;- NCI60$data # Gene expression data set\n\n\n# what if I would like to compute the mean of each gene within each tissue type?\ntissue.means &lt;- apply(nci.data, 2, function(x){tapply(x, nci.labs, mean)})\ndim(tissue.means)\n\n[1]   14 6830\n\ntable(nci.labs)\n\nnci.labs\n     BREAST         CNS       COLON K562A-repro K562B-repro    LEUKEMIA \n          7           5           7           1           1           6 \nMCF7A-repro MCF7D-repro    MELANOMA       NSCLC     OVARIAN    PROSTATE \n          1           1           8           9           6           2 \n      RENAL     UNKNOWN \n          9           1 \n\n\nCompute the PC\n\n# PCA analysis after scaling the variables to standard deviation one:\npr.out &lt;- prcomp(nci.data, scale=TRUE)\n\nPrint the summary output\n\nsummary(pr.out)\n\n\npr.var &lt;- pr.out$sdev^2\npve &lt;- pr.var/sum(pr.var)\npve &lt;- 100*pve\n\npar(mfrow=c(1,2))\nplot(pve,  type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"brown3\")\n\n\n\n\n\nHow many PCs to keep?\n\nmysel80 &lt;- which(cumsum(pve) &gt; 80)[1] # explains 80% of the variability\nmysel70 &lt;- which(cumsum(pve) &gt; 70)[1] # explains 70% of the variability\n\npar(mfrow=c(1,2)) # plot contains two smaller plots next to each other\nplot(pve,  type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nabline(v = mysel80)\nabline(v = mysel70, col=3)\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"brown3\")\nabline(v = mysel80)\nabline(h = 80)\nabline(v = mysel70, col=3)\nabline(h = 70, col=3)\n\n\n\n\nIf we decide to only keep the principal components that explains 70% of the variance, we end up with 24 components, which we can further analyse to better understand the relationships between the variables. For simplicity we only look at the first few components.\nWe plot the first few principal component score vectors, to visualize the results. The observations (cell lines) corresponding to a given cancer type will be plotted in the same colour.\n\nCols=function(vec){\n  cols=rainbow(length(unique(vec)))\n  return(cols[as.numeric(as.factor(vec))])\n}\n\n# Plot the first vs second and first vs third principal component score vectors,\n# with colors associated to labels (using the Cols() helper function)\npar(mfrow=c(1,2))\nplot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19,xlab=\"PC 1\",ylab=\" PC 2\")\nplot(pr.out$x[,c(1,3)], col=Cols(nci.labs), pch=19,xlab=\"PC 1\",ylab=\" PC 3\")\nlegend('topleft', col=rainbow(length(unique(nci.labs))), legend=unique(nci.labs), bty='n', lwd=2, cex=.6)"
  },
  {
    "objectID": "lab/lab_day4_clustering.html",
    "href": "lab/lab_day4_clustering.html",
    "title": "R Lab (day 4): Clustering",
    "section": "",
    "text": "Download datasets here or from Canvas.\nR script: Code\nLab lecture"
  },
  {
    "objectID": "lab/lab_day4_clustering.html#nci60",
    "href": "lab/lab_day4_clustering.html#nci60",
    "title": "R Lab (day 4): Clustering",
    "section": "NCI60",
    "text": "NCI60\n\nlibrary(ISLR)\nnci.labs &lt;- NCI60$labs # Sample labels (tissue type)\nnci.data &lt;- NCI60$data # Gene expression data set\n\n\nHierarchical clustering\nWe start by scaling the data, calculate the distance matrix (using the Euclidean distance), and then investigate different linkage methods.\n\n# Scale the data to zero mean and unit variance:\nsd.data &lt;- scale(nci.data)\n\n# Calculate the distance matrix (default = Euclidean):\ndata.dist &lt;- dist(sd.data)\ndata.dist &lt;- dist(sd.data, method=\"euclidean\")\n\n\n# Perform clustering\nhc.complete &lt;- hclust(data.dist, method=\"complete\")\n\n# names(hc.complete)\nplot(hc.complete, labels=nci.labs, main=\"Complete Linkage\", xlab=\"\", sub=\"\")\n\n\n\n# hc.complete$merge  # order of aggregations of samples / clusters\n# hc.complete$height # distance at which aggregations happen\n# hc.complete$order  # correct order of the samples for obtaining the plot\n# hc.complete$labels # labels (numeric, since we don't know the original categories!)\n# hc.complete$method\n# hc.complete$call\n# hc.complete$dist.method\n\nDifferent linkage methods\n\nhc.average &lt;- hclust(data.dist, method=\"average\")\nhc.single &lt;- hclust(data.dist, method=\"single\")\n\nplot(hc.average, labels=nci.labs, main=\"Average Linkage\", xlab=\"\", sub=\"\")\nplot(hc.single, labels=nci.labs,  main=\"Single Linkage\", xlab=\"\", sub=\"\")\n\n\n## First, we use cutree() to compare the results when the data are separated\n## into either 2 or 4 clusters.\n\n# Compare 2 clusters and 4 clusters:\nhc.clusters &lt;- cutree(hc.complete, c(2, 4))\ntable(hc.clusters[,\"2\"], hc.clusters[,\"4\"])\n\n   \n     1  2  3  4\n  1 40  7  0  0\n  2  0  0  8  9\n\n# How are the labels distributed between clusters:\ntable(hc.clusters[,\"4\"], nci.labs)\n\n   nci.labs\n    BREAST CNS COLON K562A-repro K562B-repro LEUKEMIA MCF7A-repro MCF7D-repro\n  1      2   3     2           0           0        0           0           0\n  2      3   2     0           0           0        0           0           0\n  3      0   0     0           1           1        6           0           0\n  4      2   0     5           0           0        0           1           1\n   nci.labs\n    MELANOMA NSCLC OVARIAN PROSTATE RENAL UNKNOWN\n  1        8     8       6        2     8       1\n  2        0     1       0        0     1       0\n  3        0     0       0        0     0       0\n  4        0     0       0        0     0       0\n\n# visualize the cuts\nplot(hc.complete, labels=nci.labs, main=\"Complete Linkage\", xlab=\"\", sub=\"\")\nabline(h=140, col=\"red\")  # 4 clusters\nabline(h=150, col=\"blue\") # 2 clusters\n\n\n\n\nFinally, we see what happens if we use unscaled data instead of scaled data, or if we use a correlation-based distance metric instead of the Euclidean distance.\nCompare the dendrograms: How different are the resulting clusterings? Do you recognise subclusters that are consistent?\n\n# Compare scaled data versus non-scaled data:\nhc.unscaled &lt;- hclust(dist(nci.data), method=\"complete\")\npar(mfrow=c(1,1))\nplot(hc.unscaled, labels=nci.labs, main=\"Complete linkage with unscaled features\", xlab=\"\", sub=\"\")\n\n\n\n# Compare Euclidean distance with correlation-based distance:\ndd &lt;- as.dist(1-cor(t(sd.data)))\nhc.corr &lt;- hclust(dd, method=\"complete\")\npar(mfrow=c(1,1))\nplot(hc.corr, labels=nci.labs, main=\"Complete linkage with correlation-based distance\", xlab=\"\", sub=\"\")\n\n\n\n\n\n\nK-means clustering\n\nset.seed(4)\nkm.out4 &lt;- kmeans(sd.data, 4, nstart=20)\nkm.out4$cluster\n\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n  4   4   4   4   4   4   4   4   4   4   4   4   4   4   4   4   4   4   4   4 \nV21 V22 V23 V24 V25 V26 V27 V28 V29 V30 V31 V32 V33 V34 V35 V36 V37 V38 V39 V40 \n  4   4   4   1   1   4   1   4   1   4   4   1   1   3   3   3   3   3   3   3 \nV41 V42 V43 V44 V45 V46 V47 V48 V49 V50 V51 V52 V53 V54 V55 V56 V57 V58 V59 V60 \n  3   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2   2   2   2   2 \nV61 V62 V63 V64 \n  2   2   2   2 \n\n\nRead the help file ?kmeans to understand what the argument nstart=20 does. Comparing an analysis with nstart=20 versus nstart=1 demonstrates how the cluster results can be improved if we allow more evaluations with different randomly chosen starting centroids.\n\n# More evaluations with different starting centroids improve the clustering:\nset.seed(3)\nkm.out &lt;- kmeans(sd.data, 3, nstart=1)\nkm.out$tot.withinss\n\n[1] 375335.1\n\nkm.out &lt;- kmeans(sd.data, 3, nstart=20)\nkm.out$tot.withinss\n\n[1] 366350.6\n\n\nCompare with hierarchical clustering\n\n# then, we can directly compare the k-means result (along rows)\n# with the hierarchical clustering result (along columns)\ntable(km.out4$cluster, hc.clusters[,\"4\"], deparse.level=2)\n\n               hc.clusters[, \"4\"]\nkm.out4$cluster  1  2  3  4\n              1 11  0  0  9\n              2  9  0  0  0\n              3  0  0  8  0\n              4 20  7  0  0\n\n\nWe can visualise the K-means clustering results of high-dimensional data by using PCA for dimension reduction first. We plot the first two principal components and colour the data points (= individual cell lines) by their assigned cluster.\n\n# first, run PCA again on the NCI60 data\npr.out &lt;- prcomp(nci.data, scale=TRUE)\n\n# more cluster options\nkm.out2 &lt;- kmeans(sd.data, 2, nstart=20)\nkm.out3 &lt;- kmeans(sd.data, 3, nstart=20)\n\n# we can now visualise the K-Means results by labelling the data points\n# in a plot of the scores of the first 2 principal components:\npar(mfrow=c(1,3))\nplot(pr.out$x[,1:2], col=(km.out2$cluster+1), main=\"K-Means with K=2\",\n     xlab=\"PC 1\", ylab=\"PC 2\", pch=20)\nplot(pr.out$x[,1:2], col=(km.out3$cluster+1), main=\"K-Means with K=3\",\n     xlab=\"PC 1\",  ylab=\"PC 2\", pch=20)\nplot(pr.out$x[,1:2], col=(km.out4$cluster+1), main=\"K-Means with K=4\",\n     xlab=\"PC 1\", ylab=\"PC 2\", pch=20)\n\n\n\n\n\n\nHeatmap\n\n## We use the scores of the PCA on the NCI60 data, to reduce dimension\n\n#  default choices\nheatmap(pr.out$x)\n\n\n\n\n\n# I use the previous dendrogram for better ordering of the patients,\n# and I remove the dendrogram for the components\nheatmap(pr.out$x, Rowv = as.dendrogram(hc.corr), Colv = NA)\n\n\n\n\n\n# I now plot less components for the sake of clarity,\n# I add the patient's tumor type, and I give a title\npar(cex.main = .7)\nheatmap(pr.out$x[,1:40], Rowv = as.dendrogram(hc.corr), Colv = NA,\n        labRow = nci.labs, main = 'Heatmap of the scores of the first 40 PCs on the NCI60 data')"
  },
  {
    "objectID": "lab/lab_day3_pca.html#gene-expression-data",
    "href": "lab/lab_day3_pca.html#gene-expression-data",
    "title": "R Lab (day 3): Principal Component Analysis",
    "section": "Gene expression data",
    "text": "Gene expression data\nCH12Ex13 from statistical learning\nConsider again the gene expression data set “Ch12Ex13.csv” (which can be also found on the book website, www.StatLearning.com) that consists of 40 tissue samples with measurements on 1,000 genes.\nThe first 20 samples are from healthy patients, while the second 20 are from a diseased group.\nLoad in the data using read.csv(). You will need to select header=F.\nAlternatively: load in the data using “Import dataset” in the upper right window, and click “no” on the “Heading” option.\nPerform a PCA of these data and visualize the results.\nNote: remember to check if the variables (genes) are on the columns in the dataset before running the PCA. If they are not: use t() to transform the dataset.\n\n# set the path to your own!\nexp.data &lt;-  read.csv(\"data/Ch12Ex13.csv\",header=FALSE)\n\n# I want each row to represent a sample, and each column a gene\nexp.data &lt;- t(exp.data)\ndim(exp.data)\n\n[1]   40 1000\n\n# should have n=40 samples/rows, and 1000 columns --&gt; OK!\ngroups &lt;- c(rep(1,20), rep(2,20)) # group variable\n\nCarry out PCA\n\n# PCA\npr.exp &lt;- prcomp(exp.data, scale=TRUE)\n\n# Plot proportion of variance explained\npr.var &lt;- pr.exp$sdev^2\npve &lt;- pr.var/sum(pr.var)\npve &lt;- 100*pve\npar(mfrow=c(1,2))\nplot(pve, type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"red\")\n\n\n\n\nLooks like most of the principal components are needed to explain the data well. Maybe we can decide to keep 25-30 components?\nCan also plot some of the first principal components\n\n# Remember the use the helper-function to get colours\nCols=function(vec){\n  cols=rainbow(length(unique(vec)))\n  return(cols[as.numeric(as.factor(vec))])\n}\n\npar(mfrow=c(1,2)) # plot-window has two small plots next to each other\nplot(pr.exp$x[,1:2], col=Cols(groups), pch=19, xlab=\"PC 1\", ylab=\" PC 2\")\nplot(pr.exp$x[,c(1,3)], col=Cols(groups), pch=19,xlab=\"PC 1\",ylab=\" PC 3\")\nlegend('topleft', col=rainbow(length(unique(groups))), legend=paste('group ',unique(groups),sep=''), bty='n', lwd=2, cex=.6)"
  },
  {
    "objectID": "lab/lab_day4_clustering.html#gene-expression-data",
    "href": "lab/lab_day4_clustering.html#gene-expression-data",
    "title": "R Lab (day 4): Clustering",
    "section": "Gene expression data",
    "text": "Gene expression data\n\n# load in the data using read.csv(). You will need to select header=F.\ndata &lt;- read.csv(\"data/Ch12Ex13.csv\", header=FALSE)\ndata &lt;- t(data) # want each row to represent a sample ... should have n=40 samples/rows\n\n\nHierarchical clustering\n\ndata.dist &lt;- dist(data) # need to compute the distance matrix\nhclust.df &lt;- hclust(data.dist, method=\"complete\" )\n#alternatives:\n#hclust.df &lt;- hclust( D, method=\"average\" )\n#hclust.df &lt;- hclust( D, method=\"single\" )\n\n\n# find the clusters\npredicted &lt;- cutree( hclust.df, k=2 )\ntrue.groups &lt;- c( rep(0,20), rep(1,20) )\n\n# How well does our clustering predict health vs. diseased\ntable(predicted, true.groups )\n\n         true.groups\npredicted  0  1\n        1 20  0\n        2  0 20\n\n\n\n\nK-means\n\npredicted.kmean &lt;- kmeans(data, 2, nstart=20)$cluster\ntable(predicted.kmean, true.groups )\n\n               true.groups\npredicted.kmean  0  1\n              1  0 20\n              2 20  0"
  },
  {
    "objectID": "lab/lab_day1_intro.html#create-a-numeric-variable",
    "href": "lab/lab_day1_intro.html#create-a-numeric-variable",
    "title": "Introduction to R",
    "section": "Create a numeric variable",
    "text": "Create a numeric variable\nTo create a variable, you type variable_name &lt;- variable_value in the console.\n\n# create a numeric variable number_1\na &lt;- 3\na\n\n[1] 3\n\n\nYou can carry out **mathematical calculation8* on numeric variables, such as exponentiate, addition, division and many more.\n\n# assign values to variables a, b, c\na &lt;- 3\nb &lt;- 4\nc &lt;- 7\n\n# calculate the average of a,b,c\n# output directly\n(a+b+c)/3\n\n[1] 4.666667\n\n# or, save into a new variable d\nd &lt;- (a+b+c)/3\nd\n\n[1] 4.666667\n\n# e to the power of a (e = 2.7182)\nexp(a)\n\n[1] 20.08554"
  },
  {
    "objectID": "lab/lab_day1_intro.html#data-types",
    "href": "lab/lab_day1_intro.html#data-types",
    "title": "Introduction to R",
    "section": "Data types",
    "text": "Data types\nIn R, there are a few types of variables. The ones you will interact with are:\n\nnumeric (real numbers): 1.2, -5\ninteger: 1, 2, 2000\ncharacter (strings): “male”, “female”\nlogical (binary, 1/0): True or False\n\nNote that code that start with # are comments, and are not evaluated.\n\n# create a numeric variable number_1\nnumber_1 &lt;- 1.2\n\n# a character variable student\nstudent &lt;- 'hadley'\n\n# a logical variable true_or_false\ntrue_or_false &lt;- T\n\nTo evaluate (or return) the variable you have created, you can either type the name of the variable, or print() with the variable name inside the bracket.\n\nnumber_1\n\n[1] 1.2\n\nprint(number_1)\n\n[1] 1.2\n\n\nYou can check the variable type using class(variable_name):\n\nclass(number_1)\n\n[1] \"numeric\"\n\nclass(student)\n\n[1] \"character\"\n\nclass(true_or_false)\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\nName your variable\n\n\n\nIt is good practice to give your variable a name that is both easy to understand, and also valid.\n\nNames are case sensitive, VariableA is not the same as variablea\nNumbers can not be a variable name by itself. Combining numbers and letters is allowed, but should start with a letter, such as variable3, but NOT 22variable\nYou can use underscores (“snake_case” naming style). In fact it encourages readability, so it is my personal favoriate.\n\nAvoid the following:\n\nOther special characters, such as dot and dollar sign: var.A, var$A have special meanings in R.\nAvoid using function names like function, list and so on. If you really can’t think of a better name, you can use names my_function, list_1 to avoid the ambiguity."
  },
  {
    "objectID": "lab/lab_day1_intro.html#vectors",
    "href": "lab/lab_day1_intro.html#vectors",
    "title": "Introduction to R",
    "section": "Vectors",
    "text": "Vectors\nA vector is a list of values; it can be numeric, and also characters and logical.\nTo create a vector, use function c().\n\n# numeric\nnum_vector &lt;- c(1, 2, 3, 4, 5)\nnum_vector\n\n[1] 1 2 3 4 5\n\n# character\nchar_vector &lt;- c('student_a', 'student_b', 'student_c')\nchar_vector\n\n[1] \"student_a\" \"student_b\" \"student_c\"\n\n# logical \nlogical_vector &lt;- c(T, F, T, F)\nlogical_vector\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\nThere are some shortcuts to create a sequence of values; not required to learn, but very useful.\n\n# numeric\n# num_vector &lt;- c(1, 2, 3, 4, 5)\nnum_vector &lt;- 1:5 # from 1 to 5\nseq(from = 1, to = 11, by = 2) # from 1 to 11, with 2 between each\n\n[1]  1  3  5  7  9 11\n\nrep(1, 5) # repeat 1 for 5 times\n\n[1] 1 1 1 1 1\n\n# character\n# char_vector &lt;- c('student_a', 'student_b', 'student_c')\nchar_vector &lt;- paste0('student_', c('a', 'b', 'c'))\nchar_vector\n\n[1] \"student_a\" \"student_b\" \"student_c\"\n\n\n\n\n\n\n\n\nTypes of elements in a vector\n\n\n\nIn a vector, types of the elements must be the same. If you try to combine multiple types of variables in the same vector, such as a numeric number and a character, R will try to convert them into the same type.\nTry to combine the following values into a vector, and see what happens.\n\n1.52, “student_a”\n1.52, TRUE (logical)\nTRUE, “student_a”\n\n\n\n\nCombine multiple vectors\nYou can combine multiple vectors using c(). For example, vec1 has 3 elements, vec2 has 2 elements (assuming that they are of the same type), combining them gives 5 elements.\n\nvec1 &lt;- c(1, 3, 5)\nvec2 &lt;- c(100, 101)\nc(vec1, vec2)\n\n[1]   1   3   5 100 101\n\n# you can also save it into a new variable, \n# so that you can access it in the future\nvec_combined &lt;- c(vec1, vec2)\nvec_combined\n\n[1]   1   3   5 100 101"
  },
  {
    "objectID": "lab/lab_day1_intro.html#matrix",
    "href": "lab/lab_day1_intro.html#matrix",
    "title": "Introduction to R",
    "section": "Matrix",
    "text": "Matrix\nA matrix can be thought of as a stack of vectors. When you collect data from \\(n\\) patients (or subjects), you measure a few aspects on each patient such as age, sex, height and smoking. Let’s say you have measured \\(p\\) aspects. This forms a matrix of size \\(n \\times p\\).\nYou might not need to create a matrix from scratch in R (because the focus of this course is data analysis); but it is helpful to understand some basic data manipulation commands.\nYou can create a matrix using matrix(), with some parameters:\n\nmatrix_1 &lt;- matrix(data = c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = T)\nmatrix_1\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\n\nYou can also create a matrix by combining two vectors of the same size, using cbind() or rbind(), which stands for “column bind” and “rowbind”.\n\nvec1 &lt;- c(1, 2)\nvec2 &lt;- c(3, 4)\n\n# bind by columnn\nmatrix_c &lt;- cbind(vec1, vec2)\nmatrix_c\n\n     vec1 vec2\n[1,]    1    3\n[2,]    2    4\n\n# bind by row\nmatrix_r &lt;- rbind(vec1, vec2)\nmatrix_r\n\n     [,1] [,2]\nvec1    1    2\nvec2    3    4"
  },
  {
    "objectID": "lab/lab_day1_intro.html#dataframe",
    "href": "lab/lab_day1_intro.html#dataframe",
    "title": "Introduction to R",
    "section": "Dataframe",
    "text": "Dataframe\nDataframe, data.frame is a format of data commonly used in data analysis with R and python. It can be considered as a matrix, but allows a mixture of data types, such as numeric and categorical measurements (age and sex).\nIn this course, you will mostly be working with dataframes.\nWe create a small dataframe of 3 subjects:\n\nSubject 1 is a 20 years-old male who has covid\nSubject 2 is a 50 years-old female who has covid\nSubject 3 is a 32 years-old male who does not have covid\n\nThis is how you can present the dataframe, where each column has a different data type.\n\nmini_data &lt;- data.frame(\n  age = c(20, 50, 32), \n  sex = c('male', 'female', 'male'), \n  has_covid = c(T, T, F)\n)\nmini_data\n\n  age    sex has_covid\n1  20   male      TRUE\n2  50 female      TRUE\n3  32   male     FALSE"
  },
  {
    "objectID": "lab/lab_day1_intro.html#dimension-of-your-data",
    "href": "lab/lab_day1_intro.html#dimension-of-your-data",
    "title": "Introduction to R",
    "section": "Dimension of your data",
    "text": "Dimension of your data\nYou can find the size of a vector with length().\nFor a matrix or dataframe, you can use dim(). It will return nrow ncol, number of rows and number of columns.\n\nvec1 &lt;- c(1, 2)\nlength(vec1)\n\n[1] 2\n\n# matrix\nmat &lt;- matrix(data = c(1, 2, 3, 4), nrow = 2, byrow = 2)\ndim(mat)\n\n[1] 2 2\n\n# dataframe\ndim(mini_data)\n\n[1] 3 3\n\n\n\n\n\n\n\n\ndim() or length()\n\n\n\nIf you use dim() on a vector, it returns NULL. Given that a vector is just a matrix with 1 row (or column), this seems insensible.\nNonetheless, dim() works on matrix objects. if you convert the vector into a matrix with nrow =1 or ncol = 1, dim() will work.\nIf you use length() on a matrix, it will return the total number of elements, i.e. ncol times nrow.\n\n\nYou can also use nrow(), ncol() to get the number of rows and columns explicitly.\n\n# ncol, nrow\n# dim(mini_data)\nnrow(mini_data)\n\n[1] 3\n\nncol(mini_data)\n\n[1] 3"
  },
  {
    "objectID": "lab/lab_day1_intro.html#accessing-elements-in-your-data",
    "href": "lab/lab_day1_intro.html#accessing-elements-in-your-data",
    "title": "Introduction to R",
    "section": "Accessing elements in your data",
    "text": "Accessing elements in your data\nFor a vector, you can access\n\nan element at a given position\nmultiple elements at given positions\n\nelements beyond, or below a certain element\n\nSometimes you might need to combine previous knowledge to get what you want (e.g. to know how many elements in total there are).\n\nletters &lt;- c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')\n\n# 3rd letter\nletters[3]\n\n[1] \"c\"\n\n# 3rd, and 5th\nletters[c(3, 5)]\n\n[1] \"c\" \"e\"\n\n# letters beyond 4\nletters[5:8] # or, letters[5:length(letters)]\n\n[1] \"e\" \"f\" \"g\" \"h\"\n\n\nFor a matrix,\n\nmatrix[r, c] to get the element on \\(r\\)-th row, \\(c\\)-th column.\nmatrix[r, ], matrix[, c] to get all the elements on \\(r\\)-th row or \\(c\\)-th column\n\n\nmat_3by3 &lt;- matrix(data = 1:9, nrow = 3, byrow = T)\nmat_3by3\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n# element (2,3)\nmat_3by3[2, 3]\n\n[1] 6\n\n# first row\nmat_3by3[1,]\n\n[1] 1 2 3\n\n\nFor a dataframe,\n\nyou can use indices (row, col) in the same way as matrices above;\nuse data$column_name, or data['column_name'] to access the entire column\n\nConventionally, each row is a subject, and each columnn is a variable (or aspect of measurement, feature, characteristic, risk factor etc).\n\nmini_data\n\n  age    sex has_covid\n1  20   male      TRUE\n2  50 female      TRUE\n3  32   male     FALSE\n\n# first row \nmini_data[1, ]\n\n  age  sex has_covid\n1  20 male      TRUE\n\n# second col\nmini_data[, 2]\n\n[1] \"male\"   \"female\" \"male\"  \n\n# via column name using $\nmini_data$age\n\n[1] 20 50 32\n\n# alternatively, \nmini_data['age']\n\n  age\n1  20\n2  50\n3  32\n\n\n\n\n\n\n\n\nFilter data based on criteria\n\n\n\nYou might have a task where you need to filter elements based on another variable: for example, select the age based on sex. This task is done in 2 steps:\n\ncreate a logical (binary, true or false) variable on sex, call it sex_indicator\nselect the elements in age vector, corresponding to sex_ind == TRUE. (The operator == evaluates whether the criteria is met)\n\nThe following example illustrates this process. You will use this a few times in the course, for example to select the height measured for men and women.\n\n\n\nage &lt;- c(55, 60, 65)\nsex &lt;- c('Male', 'Female', 'Male')\n\n# select age for only female\n# first create a variable indicating 'sex == Female'\n# i.e. if the element is Female, returns T; otherwise, F\n\nsex_indicator &lt;- sex == 'Female'\nsex_indicator\n\n[1] FALSE  TRUE FALSE\n\n# next combine age with sex_indicator, this only selects the 2nd element\nage[sex_indicator] \n\n[1] 60\n\n# you can skip the middle step:\nage[sex == 'Female']\n\n[1] 60"
  },
  {
    "objectID": "lab/lab_day1_intro.html#modify-existing-data-optional",
    "href": "lab/lab_day1_intro.html#modify-existing-data-optional",
    "title": "Introduction to R",
    "section": "Modify existing data (optional)",
    "text": "Modify existing data (optional)\n\n\n\n\n\n\nKeep your original data safe!\n\n\n\nModifying an existing data is easy, but you should be aware of the risks. In this class we only modify data we created in the class so there is little risk, but you might have your own datasets to analyse in the future.\nYou should keep your original data in a safe place, and work on copies of it.\nVersion control is a good skill to learn.\n\n\n\n# vector\n# make e into E \nletters[5] &lt;- 'E'\nletters\n\n[1] \"a\" \"b\" \"c\" \"d\" \"E\" \"f\" \"g\" \"h\"\n\n# matrix\n# make (1, 1) 20\nmat_3by3[1, 1] # originally was 1\n\n[1] 1\n\nmat_3by3[1, 1] &lt;- 20\nmat_3by3\n\n     [,1] [,2] [,3]\n[1,]   20    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n# dataframe\n# make so that subject 2 does not have covid\nmini_data\n\n  age    sex has_covid\n1  20   male      TRUE\n2  50 female      TRUE\n3  32   male     FALSE\n\nmini_data$has_covid[2] &lt;- F\nmini_data\n\n  age    sex has_covid\n1  20   male      TRUE\n2  50 female     FALSE\n3  32   male     FALSE"
  },
  {
    "objectID": "lab/lab_day1_intro.html#working-directory-r-project",
    "href": "lab/lab_day1_intro.html#working-directory-r-project",
    "title": "Introduction to R",
    "section": "Working directory, R project",
    "text": "Working directory, R project\nYou can think of the working directory as the folder where R looks for (and saves) your scripts by default.\nYou can check where your working directory by running the following command.\n\ngetwd()\n\n[1] \"/Users/andrea/Documents/GitHub/course_med3007/lab\"\n\n\nYou can manually set this to a folder of your choosing by setwd(path).\nIt is recommanded to use R project. It sets a folder just for the current tasks you work on, so that you do not need to set the working directory every time you open RStudio. Read more about how to create an R project."
  },
  {
    "objectID": "lab/lab_day1_intro.html#import-data-1",
    "href": "lab/lab_day1_intro.html#import-data-1",
    "title": "Introduction to R",
    "section": "Import data",
    "text": "Import data\nData exist in different formats,\n\ncsv is one of the most commonly used data format for tabular data. If possible, it is a good idea to use this data format as it is readable by different languages and softwares\nxlsx is also good for storing tabular data; however it is slightly more complicated than csv.\nrda can be used to store R data (such as lists, higher dimensional arrays);\nSome formats are data created by foreign softwares (such as dta created by STATA), and they would require some specific R packages to load in.\n\nIt is difficult to summarise all the data formats here, so you should check the documentation on how to import and write (save) data of different types."
  },
  {
    "objectID": "lab/lab_day1s_rstudio.html#rstudio-and-posit",
    "href": "lab/lab_day1s_rstudio.html#rstudio-and-posit",
    "title": "Getting started in RStudio",
    "section": "RStudio and Posit",
    "text": "RStudio and Posit\nRStudio is a free and open-source IDE (integrated development environment). RStudio IDE is developed by Posit, previously RStudio PBC.\nIt is convenient to download RStudio to your laptop or desktop; or use RStudio Cloud (need internet connection).\nWhen you open Rstudio, you will see something like this.\n\n\n\n\n\n\n\nEmpty bottom right panel\n\n\n\nYou might NOT see anything in the bottom right panel, because you might not have a Project yet.\nDon’t worry, we will learn how to create it."
  },
  {
    "objectID": "lab/lab_day3_pca.html#exercise-1-food",
    "href": "lab/lab_day3_pca.html#exercise-1-food",
    "title": "R Lab (day 3): Data exploration, Principal Component Analysis",
    "section": "Exercise 1: Food",
    "text": "Exercise 1: Food\nIn the first exercise, we explore a low-dimensional dataset, Food.txt.\n(This example is not a genomics example, however it is useful to illustrate important concepts in data exploration and dimensional reduction via PCA.)\nFood.txt contains data on food consumption of a variety of food categories in European counries. First load the dataset.\n\nfood &lt;- read.table('data/Food.txt', header=T)\n# we change the name from pulses to a more common name, legume\ncolnames(food)[7] &lt;- 'Legume'\nhead(food) # print first 6 lines \n\n               Meat Pigs Eggs Milk Fish Cereals Legume Fruit\nAlbania        10.1  1.4  0.5  8.9  0.2    42.3    5.5   1.7\nAustria         8.9 14.0  4.3 19.9  2.1    28.0    1.3   4.3\nBelg.Lux.      13.5  9.3  4.1 17.5  4.5    26.6    2.1   4.0\nBulgaria        7.8  6.0  1.6  8.3  1.2    56.7    3.7   4.2\nCzechoslovakia  9.7 11.4  2.8 12.5  2.0    34.3    1.1   4.0\nDenmark        10.6 10.8  3.7 25.0  9.9    21.9    0.7   2.4\n\n\n\nExplore the dataset\nThe first thing to do after loading the dataset is to get to know its content better.\nTry to find out the following information about the data:\n\nthe dimension (numbers of columns and rows)\nthe column names, and row names\n\nWe can also look at one food in particular, Fish: find the mean, maximum and minimum value for this variable. This is to investigate one column of the data.\n\ndim(food)\n\n[1] 25  8\n\ncolnames(food)\n\n[1] \"Meat\"    \"Pigs\"    \"Eggs\"    \"Milk\"    \"Fish\"    \"Cereals\" \"Legume\" \n[8] \"Fruit\"  \n\nrownames(food)\n\n [1] \"Albania\"        \"Austria\"        \"Belg.Lux.\"      \"Bulgaria\"      \n [5] \"Czechoslovakia\" \"Denmark\"        \"East.Germany\"   \"Finland\"       \n [9] \"France\"         \"Greece\"         \"Hungary\"        \"Ireland\"       \n[13] \"Italy\"          \"Netherlands\"    \"Norway\"         \"Poland\"        \n[17] \"Portugal\"       \"Romania\"        \"Spain\"          \"Sweden\"        \n[21] \"Switzerland\"    \"United.Kingdom\" \"USSR\"           \"West.Germany\"  \n[25] \"Yugoslavia\"    \n\n# explore one variable\nmean(food$Fish)\n\n[1] 4.284\n\nmax(food$Fish)\n\n[1] 14.2\n\nmin(food$Fish)\n\n[1] 0.2\n\n\nNow we investigate the data by row. Each row is a country. We can extract the data (‘filter’) for Norway, for exmaple.\nIt is also easy to get data for more than one country, such as from Denmark and Sweden.\n\n# subsetting\nfood[rownames(food) == 'Norway',]\n\n       Meat Pigs Eggs Milk Fish Cereals Legume Fruit\nNorway  9.4  4.7  2.7 23.4  9.7      23    1.6   2.7\n\nfood[rownames(food) %in% c('Norway', 'Denmark', 'Sweden'),]\n\n        Meat Pigs Eggs Milk Fish Cereals Legume Fruit\nDenmark 10.6 10.8  3.7 25.0  9.9    21.9    0.7   2.4\nNorway   9.4  4.7  2.7 23.4  9.7    23.0    1.6   2.7\nSweden   9.9  7.8  3.5 24.7  7.5    19.5    1.4   2.0\n\n\nNow we can make some simple visualizations. We can look at the distribution for each variable by making a histogram.\n\nhist(food$Fish, main = 'Histogram of Fish')\n\n\n\nhist(food$Fish, breaks = 20, main = 'Histogram of Fish')\n\n\n\nhist(food$Meat, main = 'Histogram of Meat')\n\n\n\n\nA box plot is another commonly used tool for presenting data distribution, for a few variables together. This way you can compare different foods.\n\n# las rotates the axis text 90 degrees\nboxplot(food, las = 2,\n        main = 'Food consumption across European countries')\n\n\n\n\nWe can look at pairs of food, to identify the whether there is some kind of relationship between them. For example, do countries that consume more fish also consume more meat? What about cereal and fruit?\nA scatter plot with one food on its x-axis and another on the y-axis can be useful.\nWe can add the country names on top of the scatter plot to provide more information.\n\n# two variables\nplot(food$Fish, food$Meat, pch=20, main = 'Fish vs Meat')\n\n\n\n# to add country: run this line as well\n# text(food$Fish, food$Meat, labels = rownames(food))\n\n# choose aother pair of food, add country label\nplot(food$Cereals, food$Fruit, main = 'Cereals vs Fruit')\ntext(food$Cereals, food$Fruit, labels = rownames(food))\n\n\n\n\nYou can make pair-wise scatter plots for all the food pairs. However when you have many variables, these plots become less easy to read.\n\n# pair-wise scatter\nplot(food, main = 'Pair-wise scatter plot')\n\n\n\n\n\n\nPrincipal component analysis\nWe can use principal component analysis PCA to explore the dataset, and reveal more information beyond the original data points.\nThe command we use is prcomp(data, scale).\n\ndata is the dataset to carry out PCA. Sometimes you need to do some processing such as centering and scaling.\nscale is an argument that asks the program to scale the data for us automatically. We specify it to be TRUE.\n\nAfter running the command, you can print out the results using summary.\n\n# need to scale the data\npc_food &lt;- prcomp(food, scale=TRUE)\n# pc_food\nsummary(pc_food)\n\nImportance of components:\n                          PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     1.9251 1.2073 1.0595 0.9315 0.57322 0.52889 0.35617\nProportion of Variance 0.4632 0.1822 0.1403 0.1085 0.04107 0.03497 0.01586\nCumulative Proportion  0.4632 0.6454 0.7857 0.8942 0.93527 0.97024 0.98609\n                           PC8\nStandard deviation     0.33354\nProportion of Variance 0.01391\nCumulative Proportion  1.00000\n\n\nExamine the loading (rotation). This is a \\(p \\times n_{pc}\\) matrix where each row corresponds to one feature from the original data, and each column corresponds to one principal component PC.\n\nloading_food &lt;- pc_food$rotation\n# print out the result, but only keep 2 digits\nround(loading_food, digits = 2)\n\n          PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8\nMeat    -0.33 -0.05 -0.20 -0.72 -0.48 -0.20 -0.12 -0.21\nPigs    -0.31  0.15  0.68  0.20 -0.06 -0.06 -0.37 -0.48\nEggs    -0.44 -0.07  0.23 -0.26  0.27  0.53  0.57 -0.06\nMilk    -0.41  0.15 -0.36 -0.03  0.70 -0.38 -0.15 -0.13\nFish    -0.13 -0.67 -0.32  0.40 -0.13  0.02  0.11 -0.49\nCereals  0.45  0.29  0.05 -0.13  0.06 -0.32  0.52 -0.56\nLegume   0.43 -0.17 -0.05 -0.36  0.34  0.46 -0.46 -0.32\nFruit    0.13 -0.62  0.45 -0.25  0.24 -0.46  0.06  0.23\n\n\nScores (projections) are produced by multiplying the original \\(n \\times p\\) data matrix and \\(p \\times n_{pc}\\) loading matrix. The result is a \\(n \\times n_{pc}\\) matrix where rows correspond to the rows in the original data (country names), and columns are the principal components.\nYou can visualize the points using a few selected PCs rather than the original data (next section).\n\nscores_food &lt;- pc_food$x\nround(scores_food, digits = 2)\n\n                 PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8\nAlbania         2.94  1.40 -1.60 -0.52 -1.02  0.22 -0.73  0.52\nAustria        -1.61  0.65  1.60  0.30  0.41  0.11  0.19 -0.03\nBelg.Lux.      -1.43 -0.13  0.18 -0.70 -0.46  0.27  0.28 -0.08\nBulgaria        2.70  1.02  0.32 -0.10 -0.50 -0.63  0.69 -0.26\nCzechoslovakia -0.23  0.78  1.09  0.36 -0.80 -0.38  0.15  0.17\nDenmark        -2.36 -0.34 -0.72  1.25 -0.11  0.07  0.08 -0.73\nEast.Germany   -1.03 -0.04  1.01  1.07 -0.82  0.55  0.38  0.20\nFinland        -1.49  0.92 -2.26  0.91  0.87 -0.55  0.00  0.21\nFrance         -1.46 -1.17  0.27 -1.73 -0.78 -1.10 -0.28 -0.40\nGreece          1.97 -1.50 -0.65 -1.44  1.16  0.21 -0.10 -0.52\nHungary         1.50  0.86  1.84  0.26  0.44  0.83 -0.45 -0.36\nIreland        -2.46  0.84 -0.06 -0.92  0.28  0.30  0.20  0.03\nItaly           1.22 -0.88  0.39 -0.70  0.43 -0.24  0.37  0.53\nNetherlands    -1.73  0.69  0.94  0.40  0.47 -0.02 -0.62  0.03\nNorway         -0.94 -0.66 -1.85  1.17 -0.02 -0.05  0.12  0.10\nPoland          0.22 -0.20  1.22  0.45  0.75 -1.10  0.18  0.34\nPortugal        1.83 -3.70  0.15  1.49 -0.64 -0.15 -0.35 -0.19\nRomania         2.68  1.32 -0.10  0.24  0.04  0.19 -0.16 -0.30\nSpain           1.71 -2.26  0.19 -0.27  0.44  0.77  0.23  0.63\nSweden         -1.81  0.04 -1.17  0.95  0.12  0.40 -0.05  0.03\nSwitzerland    -1.24  0.18  0.26 -0.79  0.21 -0.69 -0.61  0.22\nUnited.Kingdom -1.78 -0.21 -0.96 -2.03 -0.38  0.78  0.31 -0.08\nUSSR            1.23  0.86 -0.90 -0.05 -0.12 -0.25  0.32 -0.06\nWest.Germany   -2.01  0.20  0.88  0.03 -0.22  0.41 -0.29  0.24\nYugoslavia      3.57  1.35 -0.05  0.37  0.26  0.07  0.13 -0.24\n\n\nAnother important result from the prcomp() command is the explained variance (PVE, proportion of variance explained). All PCs explain 100% of the variance; while the first PC explains the largest proportion (46%), second PC explains the second largest proportion (18.2%) and so on.\nYou can find the variance (squared standard deviation, sdev) using the following commands. You can compare with the results from summary(), see if they correspond.\n\n# variance explained by each PC\npc_food_var &lt;- pc_food$sdev^2\n# proportion\npc_food_pve &lt;- pc_food_var/sum(pc_food_var)\n# print out, keep 3 digits\nround(pc_food_pve, digits = 3)\n\n[1] 0.463 0.182 0.140 0.108 0.041 0.035 0.016 0.014\n\n# cumulative of 1st, 2nd, ... 8th PC\ncumsum(pc_food_pve)\n\n[1] 0.4632302 0.6454168 0.7857372 0.8941976 0.9352708 0.9702365 0.9860940\n[8] 1.0000000\n\n\n\n\nVisualize PCA results\nBiplot of the principal components displays two principal components with their labels. By default, it plots the first 2 PC; but you can also select PC1, PC3 with the choices = c(1,3) argument.\nThe country labels indicate the position where the original datapoints are projected onto PC1 and PC2. The closer points are clustered together, the more similar the points are. You can find the arrows pointing towards different directions, which tells additional information as in what way countries are similar.\n\n# by default, pc1 pc2\n# set x-axis limit\n# same as biplot(pc_food, choices = c(1,2)) \nbiplot(pc_food, xlim = c(-0.5, 0.5))\n\n\n\n# choose pc1 and pc3\nbiplot(pc_food, choices = c(1,3)) \n\n\n\n\nNow we can visualize the variance explained by the PCs, and compare with the original data features (columns). We use bar plots on the variance already computed from the previous section.\nIt can be seen that the first PC corresponds to the largest variance explained, the second PC corresponds to the second largest variance explained, etc.\nOn the other hand, the original data features have different variances, and do not seem to have obvious patterns.\n\npar(mfrow = c(1, 2))\n# variance of the PCs\nbarplot(pc_food_var, las=2,\n        main='Principal components', ylab='Variances',\n        names.arg = paste('PC ',1:length(pc_food_var),sep=''))\n\n# variance of the original data variables\n# apply command here computes sd by column\nbarplot(apply(food, 2, sd)^2, las=2, main='Original Variables', ylim=c(0,150), ylab='Variances')\n\n\n\n\nLastly, you can visualize the cumulative variance explained well.\n\npar(mfrow = c(1,1))\n# PVE\nplot(cumsum(pc_food_pve), type='b', axes=F, xlab='number of components',\n     ylab='contribution to total variance', ylim=c(0,1))\nabline(h=1, col='blue')\nabline(h=0.8, lty=2, col='blue')\nbox()\naxis(2,at=0:10/10,labels=0:10/10)\naxis(1,at=1:ncol(food),labels=1:ncol(food),las=2)"
  },
  {
    "objectID": "lab/lab_day3_pca.html#exercise-2-nci60",
    "href": "lab/lab_day3_pca.html#exercise-2-nci60",
    "title": "R Lab (day 3): Data exploration, Principal Component Analysis",
    "section": "Exercise 2: NCI60",
    "text": "Exercise 2: NCI60\nNow we move to a typical large-scale biological data set.\nWe have already seen the NCI60 cancer cell line microarray data set, consisting of 6830 gene expression measurements on 64 cancer cell lines.\n\nlibrary(ISLR)\nnci.labs &lt;- NCI60$labs # Sample labels (tissue type)\nnci.data &lt;- NCI60$data # Gene expression data set\n\nnci.data contains the gene expression level measured on 6830 genes. We can find out the dimension with dim() command.\nnci.labs contains the labels for the cancer types. Note that some cancer types have more than one cell line, we can get a quick overview using table(). This counts how many times each cancer type is present in the labels.\nSince the focus of today’s topic is unsupervised learning, we do not need to pay too much attention to the labels. However we can use the labels in the end to check whether the PCA and clustering produce meaningful results.\n\ndim(nci.data)\n\n[1]   64 6830\n\ntable(nci.labs)\n\nnci.labs\n     BREAST         CNS       COLON K562A-repro K562B-repro    LEUKEMIA \n          7           5           7           1           1           6 \nMCF7A-repro MCF7D-repro    MELANOMA       NSCLC     OVARIAN    PROSTATE \n          1           1           8           9           6           2 \n      RENAL     UNKNOWN \n          9           1 \n\n# what if I would like to compute the mean of each gene within each tissue type?\ntissue.means &lt;- apply(nci.data, 2, function(x){tapply(x, nci.labs, mean)})\ndim(tissue.means)\n\n[1]   14 6830\n\n\nYou can and should carry out some exploratory analysis on the data, such as finding out the means and extreme values; this is left for home practice.\n\nCarry out PCA\nThe dataset is a high-dimensional one, that is the number of columns (features) are much larger than the number of rows (measurements). It is inpractical to analyze and search for hidden structures by looking at each one of the feature, and PCA is a useful tool to move forward.\nWe use prcomp() to produce PCA results. Set the scale = T to make sure the data is standardized to have standard deviation equal to 1 among each column.\n\n# PCA analysis after scaling the variables to standard deviation one:\npr.out &lt;- prcomp(nci.data, scale=TRUE)\n\nPrint the summary output with summary(). Note that the result is quite long, so we didn’t print out everything; but you can execute the line and see what it does.\n\nsummary(pr.out)\n\nNow we investigate the variance explained by the PCs. The y-axis in the plots below corresponds to the percentage (from 0 to 100%) explained.\n\npr.var &lt;- pr.out$sdev^2\npve &lt;- pr.var/sum(pr.var)\npve &lt;- 100*pve # display percentage\n\npar(mfrow=c(1,2))\nplot(pve,  type=\"o\", ylab=\"PVE (%)\", xlab=\"Principal Component\", col=\"blue\")\nplot(cumsum(pve), type=\"o\", ylim = c(0, 100),ylab=\"Cumulative PVE (%)\", xlab=\"Principal Component\", col=\"brown3\")\n\n\n\n\n\n\nHow many PCs to keep?\nThe maximum number of PC computed in principal component analysis is the \\(min\\{n, p\\}\\). This means, for a high dimensional problem like this one, we have at most 64 PCs.\nFor the purpose of dimensional reduction, we do not need to keep all the PCs. We can check how many PCs explain at least a certain amount of the variance. For example, we found out that the first 24 PC and first 32 PC explained 70% and 80% of the variance. We can mark it on the plots from before.\n\nmysel70 &lt;- which(cumsum(pve) &gt; 70)[1] # explains 70% \nmysel80 &lt;- which(cumsum(pve) &gt; 80)[1] # explains 80% \nc(mysel70, mysel80)\n\n[1] 24 32\n\npar(mfrow=c(1,2)) # plot contains two smaller plots next to each other\nplot(pve,  type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nabline(v = mysel80)\nabline(v = mysel70, col=3)\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"brown3\")\nabline(v = mysel80)\nabline(h = 80)\nabline(v = mysel70, col=3)\nabline(h = 70, col=3)\n\n\n\n\nIf we decide to only keep the principal components that explains 70% of the variance, we end up with 24 components, which we can further analyse to better understand the relationships between the variables. For simplicity we only look at the first few components.\nWe plot the first few principal component score vectors, to visualize the results. The observations (cell lines) corresponding to a given cancer type will be plotted in the same colour.\n\nCols=function(vec){\n  cols=rainbow(length(unique(vec)))\n  return(cols[as.numeric(as.factor(vec))])\n}\n\n# Plot the first vs second and first vs third principal component score vectors,\n# with colors associated to labels (using the Cols() helper function)\npar(mfrow=c(1,2))\nplot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19,xlab=\"PC 1\",ylab=\" PC 2\")\nplot(pr.out$x[,c(1,3)], col=Cols(nci.labs), pch=19,xlab=\"PC 1\",ylab=\" PC 3\")\nlegend('topleft', col=rainbow(length(unique(nci.labs))), legend=unique(nci.labs), bty='n', lwd=2, cex=.6)\n\n\n\n\n\n\n\n\n\n\nWhy not use biplot?\n\n\n\nYou might have realized that the plots above are essentially what biplot did in the first exercise: plotting PC1, PC2 againt each other. The reason we do not use it here is simple: by default biplot displays also the loading vectors (rotation). Given that we have 64 PCs, the final figure would be unreadable.\nYou can try to remove the loading vectors from biplot as an exercise."
  },
  {
    "objectID": "lab/lab_day3_pca.html#exercise-3-gene-expression-data",
    "href": "lab/lab_day3_pca.html#exercise-3-gene-expression-data",
    "title": "R Lab (day 3): Data exploration, Principal Component Analysis",
    "section": "Exercise 3: Gene expression data",
    "text": "Exercise 3: Gene expression data\n(CH12Ex13 from statistical learning)\nConsider again the gene expression data set “Ch12Ex13.csv” (which can be also found on the book website) that consists of 40 tissue samples with measurements on 1,000 genes.\nThe first 20 samples are from healthy patients, while the second 20 are from a diseased group.\nLoad in the data using read.csv(). You will need to select header=F.\nAlternatively: load in the data using “Import dataset” in the upper right window, and click “no” on the “Heading” option.\nPerform a PCA of these data and visualize the results.\nNote: remember to check if the variables (genes) are on the columns in the dataset before running the PCA. If they are not: use t() to transform the dataset.\n\n# set the path to your own!\nexp.data &lt;-  read.csv(\"data/Ch12Ex13.csv\",header=FALSE)\n\n# I want each row to represent a sample, and each column a gene\nexp.data &lt;- t(exp.data)\ndim(exp.data)\n\n[1]   40 1000\n\n# should have n=40 samples/rows, and 1000 columns --&gt; OK!\ngroups &lt;- c(rep(1,20), rep(2,20)) # group variable\n\nCarry out PCA\n\n# PCA\npr.exp &lt;- prcomp(exp.data, scale=TRUE)\n\n# Plot proportion of variance explained\npr.var &lt;- pr.exp$sdev^2\npve &lt;- pr.var/sum(pr.var)\npve &lt;- 100*pve\npar(mfrow=c(1,2))\nplot(pve, type=\"o\", ylab=\"PVE\", xlab=\"Principal Component\", col=\"blue\")\nplot(cumsum(pve), type=\"o\", ylab=\"Cumulative PVE\", xlab=\"Principal Component\", col=\"red\")\n\n\n\n\nLooks like most of the principal components are needed to explain the data well. Maybe we can decide to keep 25-30 components?\nCan also plot some of the first principal components\n\n# Remember the use the helper-function to get colours\nCols=function(vec){\n  cols=rainbow(length(unique(vec)))\n  return(cols[as.numeric(as.factor(vec))])\n}\n\npar(mfrow=c(1,2)) # plot-window has two small plots next to each other\nplot(pr.exp$x[,1:2], col=Cols(groups), pch=19, xlab=\"PC 1\", ylab=\" PC 2\")\nplot(pr.exp$x[,c(1,3)], col=Cols(groups), pch=19,xlab=\"PC 1\",ylab=\" PC 3\")\nlegend('topleft', col=rainbow(length(unique(groups))), legend=paste('group ',unique(groups),sep=''), bty='n', lwd=2, cex=.6)"
  },
  {
    "objectID": "lab/lab_day2_testing.html",
    "href": "lab/lab_day2_testing.html",
    "title": "R Lab (day 2): Multiple Testing",
    "section": "",
    "text": "Download datasets here or from Canvas.\nR scripts"
  },
  {
    "objectID": "lab/lab_day2_testing.html#t-test-brain-data",
    "href": "lab/lab_day2_testing.html#t-test-brain-data",
    "title": "R Lab (day 2): Multiple Testing",
    "section": "T-test: brain data",
    "text": "T-test: brain data\n\nload('data/data_brainshake.RData')\ndata &lt;- as.data.frame(mydatanew)\nhead(data)\n\n  ID kjonn Alder  BMI time tot.kol LDL.kol HDL.kol triglyserider Hexenal\n1  1     0    20 24.4   t1       5      12       2             2      35\n2  2     1    22 20.7   t1      27      22      16             5      41\n3  3     1    20 20.0   t1      18      20       6             9      31\n4  4     0    20 22.3   t1       4       6       7             3      48\n6  6     1    23 22.3   t1      20      23       5             6      30\n7  7     1    25 19.3   t1       6       5       9             6      38\n  Nonenal X8isoPGF.creat  GSH   GR    GPx   CAT X18_1_9 X18_2 X18_3 X20_4 X20_5\n1       3              1 1.18 2.80 115.76 10.11      19    39    28     8    38\n2       6             53 1.29 9.51 131.62 10.25      10    52    30    12    14\n3       2             45 1.68 6.08 111.83 11.00      47    26     7    35     3\n4       1              4 1.53 8.81  93.38  7.32      43    12     9    31    35\n6      10              5 1.02 6.86 107.73  7.86      27    44    14    12     5\n7       9             14 1.62 6.81 119.88 10.28      26    28    20    19    18\n  X22_5 X22_6\n1    20    36\n2     9    12\n3     2     6\n4    25    33\n6     3     4\n7    23    32\n\n\n\n# I use the data in the brainshake file\n# Some descriptive statistics of each variable\nsummary(data)\n\n       ID       kjonn       Alder           BMI        time       tot.kol     \n Min.   : 1.0   0: 45   Min.   :19.0   Min.   :17.30   t1:54   Min.   : 1.00  \n 1st Qu.:18.0   1:117   1st Qu.:22.0   1st Qu.:21.00   t2:54   1st Qu.: 9.00  \n Median :43.5           Median :25.0   Median :22.40   t3:54   Median :13.00  \n Mean   :41.8           Mean   :26.8   Mean   :22.63           Mean   :13.66  \n 3rd Qu.:63.0           3rd Qu.:30.0   3rd Qu.:23.80           3rd Qu.:18.00  \n Max.   :90.0           Max.   :49.0   Max.   :30.10           Max.   :30.00  \n                                                                              \n    LDL.kol         HDL.kol       triglyserider       Hexenal     \n Min.   : 1.00   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.:10.00   1st Qu.: 5.000   1st Qu.: 4.000   1st Qu.:11.00  \n Median :14.00   Median : 8.000   Median : 6.000   Median :24.00  \n Mean   :14.03   Mean   : 8.167   Mean   : 7.457   Mean   :24.27  \n 3rd Qu.:18.00   3rd Qu.:10.750   3rd Qu.:10.000   3rd Qu.:37.00  \n Max.   :27.00   Max.   :19.000   Max.   :21.000   Max.   :52.00  \n                                                                  \n    Nonenal      X8isoPGF.creat       GSH              GR        \n Min.   : 1.00   Min.   : 1.00   Min.   :0.540   Min.   : 2.800  \n 1st Qu.:11.25   1st Qu.:12.25   1st Qu.:1.180   1st Qu.: 7.058  \n Median :24.50   Median :25.50   Median :1.500   Median : 7.900  \n Mean   :24.18   Mean   :25.76   Mean   :1.523   Mean   : 7.878  \n 3rd Qu.:36.00   3rd Qu.:39.00   3rd Qu.:1.860   3rd Qu.: 8.740  \n Max.   :52.00   Max.   :54.00   Max.   :2.890   Max.   :10.580  \n                                 NA's   :7       NA's   :8       \n      GPx              CAT            X18_1_9          X18_2      \n Min.   : 81.33   Min.   : 6.950   Min.   : 1.00   Min.   : 1.00  \n 1st Qu.:106.33   1st Qu.: 8.880   1st Qu.:14.00   1st Qu.:14.00  \n Median :115.75   Median : 9.595   Median :27.00   Median :27.00  \n Mean   :115.99   Mean   : 9.615   Mean   :27.02   Mean   :27.32  \n 3rd Qu.:123.76   3rd Qu.:10.370   3rd Qu.:40.00   3rd Qu.:40.75  \n Max.   :181.79   Max.   :14.290   Max.   :55.00   Max.   :55.00  \n NA's   :7        NA's   :10                                      \n     X18_3           X20_4           X20_5           X22_5      \n Min.   : 1.00   Min.   : 1.00   Min.   : 1.00   Min.   : 1.00  \n 1st Qu.: 9.00   1st Qu.:13.25   1st Qu.:11.00   1st Qu.:11.00  \n Median :15.00   Median :26.50   Median :22.00   Median :18.00  \n Mean   :16.49   Mean   :25.93   Mean   :22.54   Mean   :18.26  \n 3rd Qu.:23.00   3rd Qu.:38.00   3rd Qu.:33.75   3rd Qu.:26.00  \n Max.   :42.00   Max.   :53.00   Max.   :49.00   Max.   :39.00  \n                                                                \n     X22_6      \n Min.   : 1.00  \n 1st Qu.:12.25  \n Median :25.00  \n Mean   :24.85  \n 3rd Qu.:36.00  \n Max.   :52.00  \n                \n\nnames(data)\n\n [1] \"ID\"             \"kjonn\"          \"Alder\"          \"BMI\"           \n [5] \"time\"           \"tot.kol\"        \"LDL.kol\"        \"HDL.kol\"       \n [9] \"triglyserider\"  \"Hexenal\"        \"Nonenal\"        \"X8isoPGF.creat\"\n[13] \"GSH\"            \"GR\"             \"GPx\"            \"CAT\"           \n[17] \"X18_1_9\"        \"X18_2\"          \"X18_3\"          \"X20_4\"         \n[21] \"X20_5\"          \"X22_5\"          \"X22_6\""
  },
  {
    "objectID": "lab/lab_day2_testing.html#exercise-1-brain-data",
    "href": "lab/lab_day2_testing.html#exercise-1-brain-data",
    "title": "R Lab (day 2): Multiple Testing",
    "section": "Exercise 1: brain data",
    "text": "Exercise 1: brain data\n\nload('data/data_brainshake.RData')\ndata &lt;- as.data.frame(mydatanew)\nhead(data)\n\n  ID kjonn Alder  BMI time tot.kol LDL.kol HDL.kol triglyserider Hexenal\n1  1     0    20 24.4   t1       5      12       2             2      35\n2  2     1    22 20.7   t1      27      22      16             5      41\n3  3     1    20 20.0   t1      18      20       6             9      31\n4  4     0    20 22.3   t1       4       6       7             3      48\n6  6     1    23 22.3   t1      20      23       5             6      30\n7  7     1    25 19.3   t1       6       5       9             6      38\n  Nonenal X8isoPGF.creat  GSH   GR    GPx   CAT X18_1_9 X18_2 X18_3 X20_4 X20_5\n1       3              1 1.18 2.80 115.76 10.11      19    39    28     8    38\n2       6             53 1.29 9.51 131.62 10.25      10    52    30    12    14\n3       2             45 1.68 6.08 111.83 11.00      47    26     7    35     3\n4       1              4 1.53 8.81  93.38  7.32      43    12     9    31    35\n6      10              5 1.02 6.86 107.73  7.86      27    44    14    12     5\n7       9             14 1.62 6.81 119.88 10.28      26    28    20    19    18\n  X22_5 X22_6\n1    20    36\n2     9    12\n3     2     6\n4    25    33\n6     3     4\n7    23    32\n\n\nSome descriptive statistics of each variable\n\nsummary(data) # summary for each variable\n\n       ID       kjonn       Alder           BMI        time       tot.kol     \n Min.   : 1.0   0: 45   Min.   :19.0   Min.   :17.30   t1:54   Min.   : 1.00  \n 1st Qu.:18.0   1:117   1st Qu.:22.0   1st Qu.:21.00   t2:54   1st Qu.: 9.00  \n Median :43.5           Median :25.0   Median :22.40   t3:54   Median :13.00  \n Mean   :41.8           Mean   :26.8   Mean   :22.63           Mean   :13.66  \n 3rd Qu.:63.0           3rd Qu.:30.0   3rd Qu.:23.80           3rd Qu.:18.00  \n Max.   :90.0           Max.   :49.0   Max.   :30.10           Max.   :30.00  \n                                                                              \n    LDL.kol         HDL.kol       triglyserider       Hexenal     \n Min.   : 1.00   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.:10.00   1st Qu.: 5.000   1st Qu.: 4.000   1st Qu.:11.00  \n Median :14.00   Median : 8.000   Median : 6.000   Median :24.00  \n Mean   :14.03   Mean   : 8.167   Mean   : 7.457   Mean   :24.27  \n 3rd Qu.:18.00   3rd Qu.:10.750   3rd Qu.:10.000   3rd Qu.:37.00  \n Max.   :27.00   Max.   :19.000   Max.   :21.000   Max.   :52.00  \n                                                                  \n    Nonenal      X8isoPGF.creat       GSH              GR        \n Min.   : 1.00   Min.   : 1.00   Min.   :0.540   Min.   : 2.800  \n 1st Qu.:11.25   1st Qu.:12.25   1st Qu.:1.180   1st Qu.: 7.058  \n Median :24.50   Median :25.50   Median :1.500   Median : 7.900  \n Mean   :24.18   Mean   :25.76   Mean   :1.523   Mean   : 7.878  \n 3rd Qu.:36.00   3rd Qu.:39.00   3rd Qu.:1.860   3rd Qu.: 8.740  \n Max.   :52.00   Max.   :54.00   Max.   :2.890   Max.   :10.580  \n                                 NA's   :7       NA's   :8       \n      GPx              CAT            X18_1_9          X18_2      \n Min.   : 81.33   Min.   : 6.950   Min.   : 1.00   Min.   : 1.00  \n 1st Qu.:106.33   1st Qu.: 8.880   1st Qu.:14.00   1st Qu.:14.00  \n Median :115.75   Median : 9.595   Median :27.00   Median :27.00  \n Mean   :115.99   Mean   : 9.615   Mean   :27.02   Mean   :27.32  \n 3rd Qu.:123.76   3rd Qu.:10.370   3rd Qu.:40.00   3rd Qu.:40.75  \n Max.   :181.79   Max.   :14.290   Max.   :55.00   Max.   :55.00  \n NA's   :7        NA's   :10                                      \n     X18_3           X20_4           X20_5           X22_5      \n Min.   : 1.00   Min.   : 1.00   Min.   : 1.00   Min.   : 1.00  \n 1st Qu.: 9.00   1st Qu.:13.25   1st Qu.:11.00   1st Qu.:11.00  \n Median :15.00   Median :26.50   Median :22.00   Median :18.00  \n Mean   :16.49   Mean   :25.93   Mean   :22.54   Mean   :18.26  \n 3rd Qu.:23.00   3rd Qu.:38.00   3rd Qu.:33.75   3rd Qu.:26.00  \n Max.   :42.00   Max.   :53.00   Max.   :49.00   Max.   :39.00  \n                                                                \n     X22_6      \n Min.   : 1.00  \n 1st Qu.:12.25  \n Median :25.00  \n Mean   :24.85  \n 3rd Qu.:36.00  \n Max.   :52.00  \n                \n\nnames(data) # column names\n\n [1] \"ID\"             \"kjonn\"          \"Alder\"          \"BMI\"           \n [5] \"time\"           \"tot.kol\"        \"LDL.kol\"        \"HDL.kol\"       \n [9] \"triglyserider\"  \"Hexenal\"        \"Nonenal\"        \"X8isoPGF.creat\"\n[13] \"GSH\"            \"GR\"             \"GPx\"            \"CAT\"           \n[17] \"X18_1_9\"        \"X18_2\"          \"X18_3\"          \"X20_4\"         \n[21] \"X20_5\"          \"X22_5\"          \"X22_6\"         \n\n\nDdescriptive plots: boxplot and histogram (for one specific variable across groups)\n\npar(mfrow=c(1,2)) # plot 2 figures side by side\nboxplot(BMI ~ kjonn, data)\nboxplot(tot.kol ~ kjonn, data)\n\n\n\nhist(data$BMI)\n\n# histogram\nBMI_group1 &lt;- data[which(data$kjonn==0),'BMI']\nBMI_group2 &lt;- data[which(data$kjonn==1),'BMI']\n\nhist(BMI_group1) #men\n\n\n\nhist(BMI_group2) #females\n\n\n\n\n\nt-test\nWe carry out a t-test to find out whether there is a significant difference for BMI between the two genders.\n\nout &lt;- t.test(data[which(data$kjonn==0),'BMI'],data[which(data$kjonn==1),'BMI'], alternative='greater')\n# much more clever syntax\nout &lt;- t.test(BMI ~ kjonn, data, alternative='greater')\nout\n\n\n    Welch Two Sample t-test\n\ndata:  BMI by kjonn\nt = 2.5952, df = 67.68, p-value = 0.005791\nalternative hypothesis: true difference in means between group 0 and group 1 is greater than 0\n95 percent confidence interval:\n 0.443913      Inf\nsample estimates:\nmean in group 0 mean in group 1 \n       23.52667        22.28462 \n\nnames(out)\n\n [1] \"statistic\"   \"parameter\"   \"p.value\"     \"conf.int\"    \"estimate\"   \n [6] \"null.value\"  \"stderr\"      \"alternative\" \"method\"      \"data.name\"  \n\nout$p.value\n\n[1] 0.00579067\n\npvalue &lt;- out$p.value\npvalue\n\n[1] 0.00579067\n\n\nYou can also just run the t-test and not save it to an object. But it is often useful to save it, because you have access to the p-values and do not need to copy paste it from the console.\n\nt.test(BMI ~ kjonn, data, alternative='greater')\n\n\n    Welch Two Sample t-test\n\ndata:  BMI by kjonn\nt = 2.5952, df = 67.68, p-value = 0.005791\nalternative hypothesis: true difference in means between group 0 and group 1 is greater than 0\n95 percent confidence interval:\n 0.443913      Inf\nsample estimates:\nmean in group 0 mean in group 1 \n       23.52667        22.28462 \n\n\nCheck normality assumption.\n\n# QQ-plots:\npar(mfrow=c(1,2)) # plot-window with two columns\nqqnorm(BMI_group1, main = 'BMI - male')\nqqline(BMI_group1)\nqqnorm(BMI_group2, main = 'BMI - female')\nqqline(BMI_group2)\n\n\n\n# test data for normality\nshapiro.test(BMI_group1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  BMI_group1\nW = 0.89644, p-value = 0.0007354\n\nshapiro.test(BMI_group2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  BMI_group2\nW = 0.88549, p-value = 5.161e-08"
  },
  {
    "objectID": "lab/lab_day2_testing.html#exercise-2",
    "href": "lab/lab_day2_testing.html#exercise-2",
    "title": "R Lab (day 2): Multiple Testing",
    "section": "Exercise 2",
    "text": "Exercise 2\nLoad the data from the file “Testfil_Rcourse.xlsx” and consider the variable vitD_v1.\n\nplot the histogram of this variable and save it, and then also plot the boxplot of vitD_v1 stratified according to gender.\n\nDoes this variable look normally distributed?\n\nPerform a t-test to verify that vitD_v1 is different across gender groups\n\n(Solution see R script MED3007_Lab1_exercise_solution.R)"
  },
  {
    "objectID": "lab/lab_day2_testing.html#exercise-3-nci60",
    "href": "lab/lab_day2_testing.html#exercise-3-nci60",
    "title": "R Lab (day 2): Multiple Testing",
    "section": "Exercise 3: NCI60",
    "text": "Exercise 3: NCI60\nNow we move to a typical large-scale biological data set which will be our running example throughout the course.\nThe NCI60 cancer cell line microarray data set consists of 6830 gene expression measurements on 64 cancer cell lines. It is available in the R package ISLR, which is the compendium R package to the book by James et al. (2013).\n(It is not really a testing example, but we use it this way for illustration)\n\nload('data/NCI60.RData')\n\nnci.labs &lt;- NCI60$labs # Sample labels (tissue type)\nnci.data &lt;- NCI60$data # Gene expression data set\n\n# some basic summary\nlength(nci.labs)\n\n[1] 64\n\ndim(nci.data)\n\n[1]   64 6830\n\ntable(nci.labs)\n\nnci.labs\n     BREAST         CNS       COLON K562A-repro K562B-repro    LEUKEMIA \n          7           5           7           1           1           6 \nMCF7A-repro MCF7D-repro    MELANOMA       NSCLC     OVARIAN    PROSTATE \n          1           1           8           9           6           2 \n      RENAL     UNKNOWN \n          9           1 \n\n\nWe create a grouping in 2 macro-groups of cancers, to test for gene expression differences across these 2 groups only. Those 2 groups should be relatively far in terms of genomic characteristics.\n\nind1 &lt;- which(nci.labs=='BREAST' | nci.labs=='OVARIAN' | nci.labs=='PROSTATE')\nind2 &lt;- which(nci.labs=='LEUKEMIA' | nci.labs=='MELANOMA' | nci.labs=='NSCLC' | nci.labs=='RENAL') # blood, skin, lung, kidney\n\ncancer.type &lt;- c(rep(1, length(ind1)), rep(2, length(ind2))) # we have two \"cancer type\" groups\nmydata &lt;- nci.data[c(ind1, ind2) , ]\ndim(mydata)\n\n[1]   47 6830\n\n\nSome descriptive statistics\n\n# mean across patients for each gene\ngenes.means &lt;- apply(mydata, 2, mean) #1=rows, 2=columns\ngenes.var &lt;- apply(mydata, 2, var)\n\nplot(genes.means, xlab = 'genes', main = 'mean across samples', ylab = 'mean expr')\nabline(h=0, col=3)\n\n\n\n# we can try to compute the within group means and plot in different colors..\ngenes.gr.means &lt;- apply(mydata, 2, function(x){tapply(x, cancer.type, mean)})\nplot(genes.gr.means[1,], xlab = 'genes', main = 'within-group mean across samples', \n     ylim = range(genes.gr.means), ylab = 'mean expr')\npoints(genes.gr.means[2,], col=2)\nabline(h=0)\n\n\n\n\n\nt-test for genes\n\nalpha &lt;- .05\npval.ttest &lt;- apply(mydata, 2, function(x){t.test(x[which(cancer.type==1)], x[which(cancer.type==2)])$p.value})\n\nInvestigate closely on one gene\n\nx &lt;- mydata[,1] #gene 1\nx1 &lt;- x[which(cancer.type==1)] #select values for group 1\nx2 &lt;- x[which(cancer.type==2)] #select values for group 2\nres &lt;- t.test(x1, x2) #do the t-test\nres #show a summary of the test result\n\n\n    Welch Two Sample t-test\n\ndata:  x1 and x2\nt = 0.27023, df = 23.473, p-value = 0.7893\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.2562172  0.3333137\nsample estimates:\n  mean of x   mean of y \n 0.01433073 -0.02421753 \n\nres$p.value #extract the p-value\n\n[1] 0.7893453\n\nhist(pval.ttest)\n\n\n\n# bit more details for nicer plotting\nhist(pval.ttest, breaks = 1/alpha, xlab = 'p-values', ylab = 'counts', \n     main = 'Histogram of t-test p-values across genes')\n\n\n\n\nThe histogram of the p-values shows nearly uniform values but we see a slight peak around 0.\n### Multiple testing correction\n\n# How many significant p-values (without any correction)\nsum(pval.ttest &lt; alpha)\n\n[1] 562\n\n# how many expected false positives?\nVexp &lt;- alpha*dim(mydata)[2]  # this is the expected value of V from the slides\nVexp\n\n[1] 341.5\n\n\nWe adjust the p-values\n\n# Simple way of calculation adjusted p-values (using p.adjust()):\npval.fwer &lt;- p.adjust(pval.ttest, method = \"bonferroni\")\npval.fdr &lt;- p.adjust(pval.ttest, method = \"BH\")\n\n# Number of significant p-values after Bonferroni correction\nsum(pval.fwer &lt; alpha) # conservative\n\n[1] 0\n\n# Number of significant p-values after BH correction\nsum(pval.fdr  &lt; alpha)\n\n[1] 0\n\n\nConclusion: no significant difference in gene expression across the groups!"
  },
  {
    "objectID": "lab/lab_day2_testing.html#exercise-4",
    "href": "lab/lab_day2_testing.html#exercise-4",
    "title": "R Lab (day 2): Multiple Testing",
    "section": "Exercise 4",
    "text": "Exercise 4\nConsider the gene expression data set “Ch10Ex11.csv” that consists of 40 tissue samples with measurements on 1,000 genes. The first 20 samples are from healthy patients, while the second 20 are from a diseased group.\n\nLoad in the data using read.csv(). You will need to select header=F.\nHave a look at the data and describe them with appropriate descriptive measures.\nYour collaborator wants to know which genes differ the most across the two groups.\n\nSuggest a way to answer this question, and apply it here."
  }
]